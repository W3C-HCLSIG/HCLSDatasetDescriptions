<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

  <head>
    <title>Dataset Descriptions: HCLS Community Profile</title>

<!--  
TODO list:

* fix References, citations
* left-align "Description" field of RDF bundle table

-->
    <link rel="stylesheet" type="text/css" href="http://www.w3.org/StyleSheets/TR/base" />
    <style type="text/css">
  table {
    border-collapse:collapse;
  }
  td, th {
    border:1px solid black;
    padding:1em;
  }  
  table#namespaces td {
    font-family: monospace;
  }
  table.definition {
    width:100%;
  }
  table.definition td.prop {
    width:10em;
  }
/*  .editorsnote::before {
    content:    "Editor's Note";
    display:    block;
    width:      150px;
    background: #F30023;
    color:  #fff;
    margin: -1.5em 0 0.5em 0;
    font-weight:    bold;
    border: 1px solid #cff6d9;
    padding:    3px 1em;
  }
  .editorsnote {
    margin: 1em 0em 1em 1em;
    padding:    1em;
    border: 2px solid #cff6d9;
  } */
pre {
  padding: 1em;
  border: 1px dashed #2f6fab;
  color: black;
  background-color: #f9f9f9;
  line-height: 1.1em;
}
   li.tocline1 {margin-left: 2ex}
   li.tocline2 {margin-left: 5ex}
.todo {
  color: red;
  background-color: yellow;
  font-weight: bold;
}
  h5 { font-style: normal; text-decoration: underline;}
    </style>
    <!-- <link rel="stylesheet" type="text/css" href="local.css" /> -->
    <!-- link rel="stylesheet" type="text/css" href="http://www.w3.org/StyleSheets/TR/Note" / -->
    
  </head>

  <body>

    <div class="head">
      <p><a href="http://www.w3.org/">
      <img src="http://www.w3.org/Icons/w3c_home" alt="W3C" height="48" width="72" /></a></p>

      <h1 id="main">Dataset Descriptions: HCLS Community Profile</h1>
      <!-- h2 class="no-num no-toc" id="w3c-doctype">W3C Working Draft 4 April 2008</h2 -->
      <dl>
	<dt>Editors working draft.</dt>

	<dt>Editors:</dt>
	      <dd>Alasdair J.G. Gray, Heriott-Watt University, UK &lt;<a href="mailto:A.J.G.Gray@hw.ac.uk">A.J.G.Gray@hw.ac.uk</a>&gt;</dd>
	      <dd>Joachim Baran, Stanford University, USA &lt;<a href="mailto:joachim.baran@gmail.com">joachim.baran@gmail.com</a>&gt;</dd>
	      <dd>M. Scott Marshall, MAASTRO Clinic, The Netherlands &lt;<a href="mailto:m.scott.marshall@maastro.nl">m.scott.marshall@maastro.nl</a>&gt;</dd>
	      <dd>Michel Dumontier, Stanford University, USA &lt;<a href="mailto:michel.dumontier@stanford.edu">michel.dumontier@stanford.edu</a>&gt;</dd>
	<dt>Contributors:</dt>
		  <dd>Vladimir Alexiev, Ontotext Corp, Bulgaria &lt;<a href="mailto:vladimir.alexiev@ontotext.com">vladimir.alexiev@ontotext.com</a>&gt;</dd>
	      <dd>Peter Ansell, CSIRO, Australia &lt;<a href="mailto:peter.ansell@csiro.au">peter.ansell@csiro.au</a>&gt;</dd> 
	      <dd>Gary D. Bader, The Donnelly Centre, University of Toronto, Canada &lt;<a href="mailto:gary.bader@utoronto.ca">gary.bader@utoronto.ca</a>&gt;</dd>
	      <dd>Asuka Bando, NBDC, Japan &lt;<a href="mailto:bando@biosciencedbc.jp">bando@biosciencedbc.jp</a>&gt;</dd>
	      <dd>Jerven Bolleman, SIB Swiss Institute of Bioinformatics, Switzerland  &lt;<a href="mailto:jerven.bolleman@isb-sib.ch">jerven.bolleman@isb-sib.ch</a>&gt;</dd>
	      <dd>Alison Callahan, Carleton University, Canada &lt;<a href="alison.callahan@carleton.ca">alison.callahan@carleton.ca</a>&gt;</dd>
	      <dd>Jos&eacute; Cruz-Toledo, Carleton University, Canada &lt;<a href="mailto:josecruztoledo@cmail.carleton.ca">josecruztoledo@cmail.carleton.ca</a>&gt;</dd>
	      <dd>Pascale Gaudet, SIB Swiss Institute of Bioinformatics, Switzerland &lt;<a href="mailto:pascale.gaudet@isb-sib.ch">pascale.gaudet@isb-sib.ch</a>&gt;</dd>
	      <dd>Erich Gombocz, IO Informatics, USA &lt;<a href="mailto:egombocz@io-informatics.com">egombocz@io-informatics.com</a>&gt;</dd>
	      <dd>Alejandra Gonzalez-Beltran, University of Oxford, UK &lt;<a href="mailto:alejandra.gonzalez.beltran@gmail.com">alejandra.gonzalez.beltran@gmail.com</a>&gt;</dd>
	      <dd>Paul Groth, VU University Amsterdam, The Netherlands &lt;<a href="mailto:p.t.groth@vu.nl"> p.t.groth@vu.nl</a>&gt;</dd>
	      <dd>Melissa Haendel, Oregon Health and Science University, USA &lt;<a href="mailto:haendel@ohsu.edu">haendel@ohsu.edu</a>&gt;</dd>
	      <dd>Maori Ito, NIBIO, Japan &lt;<a href="mailto:maori@nibio.go.jp">maori@nibio.go.jp</a>&gt;</dd>
	      <dd>Simon Jupp, EMBL-EBI, UK &lt;<a href="mailto:jupp@ebi.ac.uk">jupp@ebi.ac.uk</a>&gt;</dd>
	      <dd>Nick Juty, EMBL-EBI, UK &lt;<a href="mailto:juty@ebi.ac.uk">juty@ebi.ac.uk</a>&gt;</dd>
	      <dd>Toshiaki Katayama, Database Center for Life Sciences, Japan &lt;<a href="mailto:ktym@dbcls.jp">ktym@dbcls.jp</a>&gt;</dd>
		  <dd>Norio Kobyashi, RIKEN, Japan &lt;<a href="mailto:norio.kobayashi@riken.jp">norio.kobayashi@riken.jp</a>&gt;</dd>
	      <dd>Kalpana Krishnaswami, Metaome, USA &lt;<a href="mailto:kalpana@metaome.com">kalpana@metaome.com</a>&gt;</dd>
	      <dd>Camille Laibe, EMBL-EBI, UK &lt;<a href="mailto:laibe@ebi.ac.uk">laibe@ebi.ac.uk</a>&gt;</dd>
	      <dd>Nicolas Le Nov&egrave;re, Babraham Institute, UK &lt;<a href="mailto:n.lenovere@gmail.com">n.lenovere@gmail.com</a>&gt;</dd>
	      <dd>Simon Lin, Marshfield Clinic Research Foundation, USA &lt;<a href="mailto:lin.simon@mcrf.mfldclin.edu">lin.simon@mcrf.mfldclin.edu</a>&gt;</dd>
	      <dd>James Malone, EMBL-EBI, UK &lt;<a href="mailto:malone@ebi.ac.uk">malone@ebi.ac.uk</a>&gt;</dd>
	      <dd>Michael Miller, Institute for Systems Biology, USA &lt;<a href="mailto:mmiller@systemsbiology.org">mmiller@systemsbiology.org</a>&gt;</dd>
	      <dd>Chris Mungall, Lawrence Berkeley National Laboratory, USA &lt;<a href="mailto:cjm@berkeleybop.org">cjm@berkeleybop.org</a>&gt;</dd>
	      <dd>Laurens Rietveld, VU University Amsterdam, The Netherlands &lt;<a href="mailto:laurens.rietveld@vu.nl">laurens.rietveld@vu.nl</a>&gt;</dd>
          <dd>Sarala M. Wimalaratne, EMBL-EBI, UK &lt;<a href="mailto:sarala@ebi.ac.uk">sarala@ebi.ac.uk</a>&gt;</dd>
		  <dd>Atsuko Yamaguchi, Database Center for Life Sciences, Japan &lt;<a href="mailto:atsuko@dbcls.jp">atsuko@dbcls.jp</a>&gt;</dd>
      </dl>

      <p class="copyright"><a href="http://www.w3.org/Consortium/Legal/ipr-notice#Copyright">Copyright</a> &#169; 2014 <a href="http://www.w3.org/"><acronym title="World Wide Web Consortium">W3C</acronym></a><sup>&#174;</sup> (<a href="http://www.csail.mit.edu/"><acronym title="Massachusetts Institute of Technology">MIT</acronym></a>, <a href="http://www.ercim.org/"><acronym title="European Research Consortium for Informatics and Mathematics">ERCIM</acronym></a>, <a href="http://www.keio.ac.jp/">Keio</a>, <a href="http://ev.buaa.edu.cn/">Beihang</a>), All Rights Reserved. W3C <a href="http://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer">liability</a>, <a href="http://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks">trademark</a> and <a href="http://www.w3.org/Consortium/Legal/copyright-documents">document use</a> rules apply.</p>

    </div>

    <hr title="Separator for header" />
    <div>
      <h2 class="notoc" id="abstract">Abstract</h2>
      <p>Access to consistent, high-quality metadata is critical to finding, understanding, and reusing scientific data. This document describes a consensus among participating stakeholders in the Health Care and the Life Sciences domain on the description of datasets using the Resource Description Framework (RDF). This specification meets key functional requirements, reuses existing vocabularies to the extent that it is possible, and addresses elements of data description, versioning, provenance, discovery, exchange, query, and retrieval. 
      </p>
    </div>

    <div>
      <h2 id="status">Status of This Document</h2>

      <p>This is an editor's draft of a document for the <a href="../..">Semantic Web in Health Care and Life Sciences Interest Group (HCLSIG)</a>. This is a live document and is subject to change without notice. It reflects the best effort of the editors to reflect implementation experience and incorporate input from various members of the IG, but is not yet endorsed by the IG as a whole. This document is not endorsed by the W3C or its member companies.</p>

    </div>
    <hr />

    <div class="toc">
      <h2 id="contents">Table of Contents</h2>
      
      <ul class="toc">
          <li class="tocline1"><a href="#introduction">1 Introduction</a> </li>
          <li class="tocline1"><a href="#scope">2 Scope</a> </li>
          <li class="tocline1"><a href="#conventions">3 Conventions</a> </li>
          <li class="tocline1"><a href="#functionalrequirements">4 Functional Requirements</a> </li>
              <li class="tocline2"><a href="#s4_1">4.1 Dataset Identification, Description, Licensing, and Provenance</a></li>
              <li class="tocline2"><a href="#s4_2">4.2 Dataset Discovery (via Catalog)</a></li>
              <li class="tocline2"><a href="#s4_3">4.3 Exchange of Dataset Descriptions</a></li>
              <li class="tocline2"><a href="#s4_4">4.4 Dataset Linking</a></li>
              <li class="tocline2"><a href="#s4_5">4.5 Content Summary</a></li>
              <li class="tocline2"><a href="#s4_6">4.6 Monitoring of Dataset Changes</a></li>
          <li class="tocline1"><a href="#datasetdescriptionlevels">5 Dataset Description Levels</a> </li>
          <li class="tocline1"><a href="#metadataguidancenotes">6 Metadata Guidance Notes</a> </li>
              <li class="tocline2"><a href="#s6_1">6.1 Literals</a></li>
              <li class="tocline2"><a href="#s6_2">6.2 Core Metadata</a></li>
              <li class="tocline2"><a href="#s6_3">6.3 Identifiers</a></li>
              <li class="tocline2"><a href="#s6_4">6.4 Provenance and Change</a></li>
              <li class="tocline2"><a href="#s6_5">6.5 Availability and Distributions</a></li>
              <li class="tocline2"><a href="#s6_6">6.6 Statistics</a></li>
          <li class="tocline1"><a href="#usageNotes">7 Using Dataset Descriptions</a></li>
              <li class="tocline2"><a href="#s7n_1">7.1 Workflows</a></li>
          <li class="tocline1"><a href="#toolingsupport">8 Tooling Support</a> </li>
              <li class="tocline2"><a href="#s7_1">8.1 Dataset Description Generation Tool</a></li>
              <li class="tocline2"><a href="#s7_2">8.2 Validation Tool</a></li>
          <li class="tocline1"><a href="#usecases">9 Use Cases</a> </li>
              <li class="tocline2"><a href="#s8_1">9.1 Marshfield Use Case</a></li>
              <li class="tocline2"><a href="#s8_2">9.2 Metaome Transcriptomics Use Case</a></li>
              <li class="tocline2"><a href="#s8_3">9.3 Radiotherapy Research Use Case</a></li>
              <li class="tocline2"><a href="#s8_4">9.4 Computational Network Biology</a></li>
              <li class="tocline2"><a href="#s8_5">9.5 Safety Information Evaluation and Visual Exploration ("SIEVE")</a></li>
              <li class="tocline2"><a href="#s8_6">9.6 Sampling Large RDF Graphs</a></li>
              <li class="tocline2"><a href="#s8_7">9.7 Query Formulation Using Data Metrics</a></li>
              <li class="tocline2"><a href="#s8_8">9.8 Data Providers</a></li>
              <li class="tocline2"><a href="#s8_9">9.9 Data Catalogs</a></li>
              <li class="tocline2"><a href="#s8_10">9.10 Experimental Datasets Use Case</a></li>
          <li class="tocline1"><a href="#acknowledgements">10 Acknowledgements</a></li>
          <li class="tocline1"><a href="#references">11 References</a></li>
          <li class="tocline1"><a href="#appendix">12 Appendix</a></li>
              <li class="tocline2"><a href="#appendix_1">12.1 Complete Example of a Dataset Description</a></li>
      </ul>
    </div>

    <!--
    <h3 id="appendices">Appendices</h3>
    <ul class="toc">
      <li class="tocline2"><a href="#rdfbundles">A RDF Sources</a></li>
      <li class="tocline2"><a href="#chlog">Change Log</a></li>
    </ul>
    -->
    <hr />


    <h2 id="introduction">1 Introduction</h2>
    <p>Big Data presents an exciting opportunity to pursue large-scale analyses over collections of data in order to uncover valuable insights across a myriad of fields and disciplines. Yet, as more and more data is made available, researchers are finding it increasingly difficult to discover and reuse these data.  One problem is that <strong>data are insufficiently described</strong> to understand what they are or how they were produced. A second issue is that <strong>no single vocabulary provides all key metadata fields</strong> required to support basic scientific use cases. A third issue is that <strong>data catalogs and data repositories all use different metadata standards</strong>, if they use any standard at all, and this prevents easy search and aggregation of data. Therefore, we need a guide to indicate what are the essential metadata for a dataset description, and the manner in which we can express it.</p>
    <p>For the purposes of this document, we <strong>define a dataset</strong> as  "A collection of data, available for access or download in one or more formats" [<a href="#DCAT">DCAT</a>]. For instance, a dataset may be generated as part of some scientific investigation, whether tabulated from observations, generated by an instrument, obtained via analysis, created through a mashup, or enhanced or changed in some manner. Research data are available in research publications and supplemental documents, in literature curated databases such as PharmGKB or the CTD,  from research repositories such as BioMedCentral-BGI GigaScience [<a href="#GigaScience">GigaScience</a>], Nature Publishing Group’s Scientific Data [<a href="#ScientificData">ScientificData</a>], Dryad Digital Repository [<a href="#Dryad">Dryad</a>], FigShare [<a href="#FigShare">FigShare</a>], Harvard Dataverse [<a href="#Dataverse">Dataverse</a>]. Cross-repository access is possible through data catalogs such as Neuroscience Information Framework (NIF) [<a href="#NIF">NIF</a>], BioSharing [<a href="#BioSharing">BioSharing</a>], Identifiers.org Registry [<a href="#Identifiers.org">Identifiers.org</a>], Integbio Database Catalog [<a href="#Integbio">Integbio</a>], Force11 [<a href="#Force11">Force11</a>], and CKAN's datahub [<a href="#Datahub">Datahub</a>].</p>
    <p>While several vocabularies are relevant in describing datasets, none are sufficient to completely provide the breadth of requirements identified in Health Care and the Life Sciences. The Dublin Core Metadata Initiative (DCMI) [<a href="#DCMI">DCMI</a>] Metadata Terms offers a broad set of types and relations for capturing document metadata. The Data Catalog Vocabulary (DCAT) [<a href="#DCAT">DCAT</a>] is used to describe datasets in catalogs, but does not deal with the issue of dataset evolution and versioning. The Provenance Ontology (PROV) [<a href="#PROV">PROV</a>] can be used to capture information about entities, activities, and people involved in producing a piece of data or thing. The Vocabulary of Interlinked Datasets (VOID) [<a href="#VOID">VOID</a>] is an RDF Schema (RDFS) [<a href="#RDFS">RDFS</a>] vocabulary for expressing metadata about Resource Description Framework (RDF) [<a href="#RDF">RDF</a>] datasets. Schema.org has a limited proposal for dataset descriptions [<a href="#SCHEMA">SCHEMA</a>]. Thus, there is need to combine these vocabularies in a comprehensive manner that meets the needs of data registries, data producers, and data consumers.</p>
    <p>Here we describe the results of a multi-stakeholder effort under the auspices of the W3C Semantic Web for Health Care and Life Sciences [<a href="#HCLS">HCLS</a>] Interest Group to produce a specification for the description of datasets that meets key functional requirements, uses existing vocabularies, and is expressed using the Resource Description Framework [<a href="#RDF">RDF</a>]. We discuss elements of data description including provenance and versioning, and describe how these can be used for data discovery, exchange, and query (with SPARQL [<a href="#SPARQL">SPARQL</a>]). This then enables the retrieval and reuse of data to encourage reproducible science.</p>
    <p>
    Specifically, we provide
    </p>
    <ul>
    <li>A community specification for describing datasets (<a href="#datasetdescriptionlevels">Section 5</a>) in RDF with detailed guidance notes (<a href="#metadataguidancenotes">Section 6</a>).</li>
    <li>Detailed requirements (<a href="#functionalrequirements">Section 4</a>) that have been drawn from a wide range of use cases (<a href="#usecases">Section 8</a>).</li>
    </ul>

    <h2 id="scope">2 Scope</h2>

    <p>This document focuses on common data elements and their value sets for the description of data. Although use cases are drawn from Health Care and the Life Sciences, this document will focus on requirements that are broadly applicable.</p>

    <h2 id="conventions">3 Conventions</h2>

    <p>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED",  "MAY", and "OPTIONAL" in this document are to be interpreted as described in RFC 2119 [<a href="#RFC2119">RFC2119</a>].</p>

    <p>RDF data in this document are expressed in Turtle [<a href="#ref-TURTLE">TURTLE</a>]. Queries on this data are expressed in SPARQL [<a href="#SPARQL">SPARQL</a>]. The following namespace prefix bindings are assumed unless otherwise stated:</p>
    <div style="text-align: center;">
      <table style="border-collapse: collapse; border-color: #000000" border="1" cellpadding="5">
	<tr><th>Prefix</th>				<th>URI</th>	  <th>Description</th></tr>
	<tr><td><code>cito:</code></td>			<td><code>http://purl.org/spar/cito/</code></td>	<td><a href="http://purl.org/spar/cito/">Citation Typing Ontology</a></td></tr>
	<tr><td><code>dcat:</code></td>			<td><code>http://www.w3.org/ns/dcat#</code></td>	<td><a href="http://www.w3.org/TR/vocab-dcat/">Data Catalog</a></td></tr>
	<tr><td><code>dctypes:</code></td>		<td><code>http://purl.org/dc/dcmitype/</code></td>	<td><a href="http://purl.org/dc/dcmitype/">Dublin Core Metadata Types</a></td></tr>
	<tr><td><code>dct:</code></td>			<td><code>http://purl.org/dc/terms/</code></td>	<td><a href="http://purl.org/dc/terms/">Dublin Core Metadata Terms</a></td></tr>
	<tr><td><code>foaf:</code></td>			<td><code>http://xmlns.com/foaf/0.1/</code></td>	<td><a href="http://xmlns.com/foaf/0.1/">Friend-of-a-Friend</a></td></tr>
	<tr><td><code>freq:</code></td>			<td><code>http://purl.org/cld/freq/</code></td>	<td><a href="http://dublincore.org/groups/collections/frequency/">Collection Description Frequency Vocabulary</a></td></tr>
	<tr><td><code>idot:</code></td>			<td><code>http://identifiers.org/idot/</code></td>	<td><a href="http://identifiers.org/idot/">Identifiers.org vocabulary</a></td></tr>
	<tr><td><code>lexvo:</code></td>		<td><code>http://lexvo.org/ontology#</code></td>	<td><a href="http://www.lexvo.org/">Lexical Vocabulary</a></td></tr>
	<tr><td><code>pav:</code></td>			<td><code>http://purl.org/pav/</code></td>	<td><a href="https://code.google.com/p/pav-ontology/wiki/Homepage">Provenance Authoring and Versioning ontology</a></td></tr>
	<tr><td><code>prov:</code></td>			<td><code>http://www.w3.org/ns/prov#</code></td>	<td><a href="http://www.w3.org/TR/prov-o/">PROV Ontology</a></td></tr>
	<tr><td><code>rdf:</code></td>			<td><code>http://www.w3.org/1999/02/22-rdf-syntax-ns#</code></td>	<td><a href="http://www.w3.org/TR/REC-rdf-syntax/">RDF Syntax</a></td></tr>
	<tr><td><code>rdfs:</code></td>			<td><code>http://www.w3.org/2000/01/rdf-schema#</code></td>	<td><a href="http://www.w3.org/TR/rdf-schema/">RDF Schema</a></td></tr>
	<tr><td><code>schemaorg:</code></td>		<td><code>http://schema.org/</code></td>		<td><a href="http://schema.org/">schema.org vocabulary</a></td></tr>
	<tr><td><code>sd:</code></td>			<td><code>http://www.w3.org/ns/sparql-service-description#</code></td>	<td><a href="http://www.w3.org/TR/sparql11-service-description/">SPARQL 1.1 Service Description</a></td></tr>
	<tr><td><code>sio:</code></td>		<td><code>http://semanticscience.org/resource/</code></td>		<td><a href="http://sio.semanticscience.org/">Semanticscience Integrated Ontology (SIO)</a></td></tr>
	<tr><td><code>xsd:</code></td>			<td><code>http://www.w3.org/2001/XMLSchema#</code></td>	<td><a href="http://www.w3.org/TR/xmlschema11-2/">XML Schema</a></td></tr>
	<tr><td><code>void:</code></td>			<td><code>http://www.w3.org/TR/void/</code></td>	<td><a href="http://www.w3.org/TR/void/">Describing Linked Datasets with the VoID Vocabulary</a></td></tr>
	<tr><td><code>void-ext:</code></td>			<td><code>http://ldf.fi/void-ext#</code></td>	<td><a href="http://ldf.fi/void-ext">Extensions to the Vocabulary of Interlinked Datasets (VoID)</a></td></tr>

	</table>
    </div>

    <p>The character sequence "###" is used to denote a placeholder for a positive integer (&ge; 1) in examples. The integers that replace this surrogate are of type <a href="http://www.w3.org/TR/xmlschema11-2/#integer">xsd:integer</a>.</p>

    <h2 id="functionalrequirements">4 Functional Requirements</h2>

    <p>In this section we describe a set of essential functionality that the dataset descriptions must provide.</p>

    <h3 id="s4_1">4.1 Dataset Identification, Description, Licensing and Provenance</h3>

    <p>High quality data descriptions are necessary to understand the nature and provenance of data including what the data is, the format the data is represented with, where the data can be retrieved from, what license is associated with the dataset, how it was generated, when it was generated, and who generated it. Importantly, such dataset descriptions should provide globally unique identifiers for specific versions and formats of datasets so that they may be used and referenced by others in downstream analyses.</p>

    <h3 id="s4_2">4.2 Dataset Discovery (via Catalog)</h3>

    <p>Data consumers need an easy mechanism to find datasets of interest. Data catalogs, identifier indices, and data standard registries such as BioSharing [<a href="#BioSharing">BioSharing</a>], identifiers.org Registry [<a href="#Identifiers.org">Identifiers.org</a>], datahub.io [<a href="#Datahub">Datahub</a>], NIF [<a href="#NIF">NIF</a>] are all important infrastructure that make it easier for users to find relevant data and even discuss their quality or utility. The availability of rich metadata will enable users to perform faceted searches of data items by placing restrictions on the values of specific metadata fields.</p>

    <h3 id="s4_3">4.3 Exchange of Dataset Descriptions</h3>

    <p>Dataset descriptions should be in a standardized format that enables facile exchange between data providers. This allows data catalogs to synchronize and specialize their offerings. For example, BioDBCore [<a href="#BioDBCore">BioDBCore</a>, <a href="#Gaudetetal2010">Gaudet et al 2010</a>] is a community-driven effort overseen by the International Society for Biocuration [<a href="#ISB">ISB</a>], which defines a checklist, or minimum information standard, including the core attributes for the description of biological databases. </p>

    <h3 id="s4_4">4.4 Dataset Linking</h3>

    <p>The integration of data typically involves establishing a similarity between resources described in different datasets. Since datasets naturally evolve with time, it is important that information regarding the nature of the linking can be adequately captured, e.g. the version and format of files and software used to generate the links.</p>

    <p>A dataset may incorporate, or link to, data in other datasets, e.g. in the creation of a data mashup. Rather than repeating the dataset description of the source datasets, the derived dataset would link to the dataset description of the specific instance that they loaded.</p>

    <h3 id="s4_5">4.5 Content Summary</h3>

    <p>A breakdown of the entities and their relationships in a dataset is useful for communicating the structure and content of the dataset. This information can be used to enable dataset navigation, facilitate query construction and compare different versions of a dataset.</p>

    <h3 id="s4_6">4.6 Monitoring of Dataset Changes</h3>

    <p>The reproducibility of scientific investigations is often tied to the availability of the original data. However, as original dataset grow or change with time, it becomes important to understand what changes have occurred and how these may affect dependent analyses. A dataset description should provide the means by which to compare different dataset versions.</p>

    <h2 id="datasetdescriptionlevels">5 Dataset Description Levels</h2>

    <p>In this section, we describe the W3C HCLS [<a href="#HCLS">HCLS</a>] recommendation for rich descriptions of datasets. There are three levels, each covering a different type of resource describing the data:</p>

    <ul>
    <li><strong>Summary Level</strong>: The summary level provides a description of a dataset that is independent of a specific version or format.</li>
    <li><strong>Version Level</strong>: The version level captures version-specific characteristics of a dataset.</li>
    <li><strong>Distribution Level</strong>: The distribution level captures metadata about a specific form and version of a dataset.</li>
    </ul>

    <p style="text-align: center">
    <img src="Figure1.png" alt="Figure 1: An overview of the relationships between dataset description levels. A single summary level description for a dataset will be related to one or more version level descriptions using dct:isVersionOf. Incremental versions may be specified using pav:previousVersion. Each version level description will be linked to one or more distribution level descriptions using dcat:distribution. Derivative and augmented datasets, or dataset mash-ups, make use of dct:source to denote their source datasets."></img><br />
    Figure 1: An overview of the relationships between dataset description levels. A single summary level description for a dataset will be related to one or more version level descriptions using dct:isVersionOf. Incremental versions may be specified using pav:previousVersion. Each version level description will be linked to one or more distribution level descriptions using dcat:distribution. Derivative and augmented datasets, or dataset mash-ups, make use of dct:source to denote their source datasets.
    </p>

    <p>Note that a distribution is the realisation of the data in a specific file format. The different distributions of a dataset may not be semantically equivalent due to differences between the data formats. For example, a chemical dataset may be released as a rich RDF dataset but also as an <a href="http://en.wikipedia.org/wiki/Chemical_table_file#SDF">SD file</a>. In this case, the SD file will not contain the same data content as the RDF dataset.</p>

    <p>The properties expected for each metadata profile are given in the table below.</p>

    <table style="text-align: center">
    <tr>
        <th>Element</th>
        <th>Property</th>
        <th>Value</th>
        <th>Summary Level</th>
        <th>Version Level</th>
        <th>Distribution Level</th>
    </tr>
    <tr>
        <td><u>Core Metadata</u></td>
		<td colspan="5"></td>
    </tr>
    <tr>
        <td>Type declaration</td>
        <td>rdf:type</td>
        <td>dctypes:Dataset</td>
        <td>MUST</td>
        <td>MUST</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>Type declaration</td>
        <td>rdf:type</td>
        <td>void:Dataset or dcat:Distribution</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MUST</td>
    </tr>
    <tr>
        <td>Title</td>
        <td>dct:title</td>
        <td>rdf:langString</td>
        <td>MUST</td>
        <td>MUST</td>
        <td>MUST</td>
    </tr>
    <tr>
        <td></td>
        <td>dct:alternative</td>
        <td>rdf:langString</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Description</td>
        <td>dct:description</td>
        <td>rdf:langString</td>
        <td>MUST</td>
        <td>MUST</td>
        <td>MUST</td>
    </tr>
    <tr>
        <td>Creators</td>
        <td>dct:creator or pav:createdBy</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST</td>
        <td>MUST</td>
    </tr>
    <tr>
        <td>Contributors</td>
        <td>dct:contributor or pav:authoredBy or pav:curatedBy</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Date created</td>
        <td>dct:created or pav:createdOn</td>
        <td><a href="http://www.w3.org/2000/01/rdf-schema#Literal">rdfs:Literal</a> encoded using the relevant <a href="http://www.w3.org/TR/NOTE-datetime">ISO 8601 Date and Time compliant string</a> and typed using the appropriate <a href="http://www.w3.org/TR/xmlschema-2/">XML Schema datatype</a></td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
        <td>SHOULD</td>
    </tr>

    <tr>
        <td>Other dates</td>
        <td>pav:authoredOn or pav:curatedOn</td>
        <td>xsd:dateTime, xsd:date, xsd:gYearMonth, or xsd:gYear</td>
        <td>MUST NOT</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Publisher</td>
        <td>dct:publisher</td>
        <td>IRI</td>
        <td>MUST</td>
        <td>MUST</td>
        <td>MUST</td>
    </tr>
    <tr>
        <td>Date of issue</td>
        <td>dct:issued</td>
        <td><a href="http://www.w3.org/2000/01/rdf-schema#Literal">rdfs:Literal</a> encoded using the relevant <a href="http://www.w3.org/TR/NOTE-datetime">ISO 8601 Date and Time compliant string</a> and typed using the appropriate <a href="http://www.w3.org/TR/xmlschema-2/">XML Schema datatype</a></td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>HTML page</td>
        <td>foaf:page</td>
        <td>IRI</td>
        <td>SHOULD</td>
        <td>SHOULD</td>
        <td>SHOULD</td>
    </tr>
    <tr>
    	<td>Logo</td>
    	<td>schemaorg:logo</td>
    	<td>IRI</td>
    	<td>SHOULD</td>
    	<td>SHOULD</td>
    	<td>SHOULD</td>
    </tr>
    <tr>
        <td>License</td>
        <td>dct:license</td>
        <td>IRI</td>
        <td>MAY</td>
        <td>SHOULD</td>
        <td>MUST</td>
    </tr>
    <tr>
        <td>Rights</td>
        <td>dct:rights</td>
        <td>rdf:langString</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Language</td>
        <td>dct:language</td>
        <td><a>http://lexvo.org/id/iso639-3/{tag}</a></td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>Concept descriptors</td>
        <td>dcat:theme</td>
        <td>IRI of type skos:Concept</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Keywords</td>
        <td>dcat:keyword</td>
        <td>xsd:string</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Vocabulary used</td>
        <td>void:vocabulary</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>Standards used</td>
        <td>dct:conformsTo</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MAY</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>References</td>
        <td>dct:references</td>
        <td>IRI</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Citations</td>
        <td>cito:citesAsAuthority</td>
        <td>IRI</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Related material</td>
        <td>rdfs:seeAlso</td>
        <td>IRI</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Partitions</td>
        <td>dct:hasPart</td>
        <td>IRI</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MUST NOT</td>
    </tr>
    <tr>
        <td><u>Identifiers</u></td>
		<td colspan="6"></td>
    </tr>
    <tr>
        <td>Preferred prefix</td>
        <td>idot:preferredPrefix</td>
        <td>xsd:string</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Alternate prefix</td>
        <td>idot:alternatePrefix</td>
        <td>xsd:string</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Identifier pattern</td>
        <td>idot:identifierPattern</td>
        <td>xsd:string</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>URI pattern</td>
        <td>void:uriRegexPattern</td>
        <td>xsd:string</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>File access pattern</td>
        <td>idot:accessPattern</td>
        <td>idot:AccessPattern</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Example identifier</td>
        <td>idot:exampleIdentifier</td>
        <td>xsd:string</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>Example resource</td>
        <td>void:exampleResource</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td><u>Provenance and Change</u></td>
		<td colspan="6"></td>
    </tr>
    <tr>
        <td>Item listing</td>
        <td>sio:has-data-item</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>Version identifier</td>
        <td>pav:version</td>
        <td>xsd:string</td>
        <td>MUST NOT</td>
        <td>MUST</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>Version linking</td>
        <td>dct:isVersionOf</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST</td>
        <td>MUST NOT</td>
    </tr>
    <tr>
        <td>Version linking</td>
        <td>pav:previousVersion</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>Version linking</td>
        <td>pav:hasCurrentVersion</td>
        <td>IRI</td>
        <td>MAY</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
    </tr>
    <tr>
        <td>Source provenance</td>
        <td>dct:source or pav:retrievedFrom or prov:wasDerivedFrom or pav:createdWith</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>Update frequency</td>
        <td>dct:accrualPeriodicity</td>
        <td>IRI of type dctypes:Frequency</td>
        <td>SHOULD</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
    </tr>
    <tr>
        <td><u>Availability/Distributions</u></td>
        <td colspan="6"></td>
    </tr>
    <tr>
        <td>Distribution description</td>
        <td>dcat:distribution</td>
        <td>IRI of Distribution Level description</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
        <td>MUST NOT</td>
    </tr>
    <tr>
        <td>Documentation</td>
        <td>dcat:landingPage</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>File format</td>
        <td>dct:format</td>
        <td>IRI or xsd:String </td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MUST</td>
    </tr>
    <tr>
        <td>File directory</td>
        <td>dcat:accessURL</td>
        <td>IRI</td>
        <td>MAY</td>
        <td>MAY</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>File URL</td>
        <td>dcat:downloadURL</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>RDF File URL</td>
        <td>void:dataDump</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>SPARQL endpoint</td>
        <td>void:sparqlEndpoint</td>
        <td>IRI</td>
        <td>SHOULD</td>
        <td>SHOULD NOT</td>
        <td>SHOULD NOT</td>
    </tr>    
	<tr>
        <td><u>Statistics</u></td>
        <td colspan="6"></td>
    </tr>
    <tr>
        <td># of triples</td>
        <td>void:triples</td>
        <td>xsd:integer</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td># of typed entities</td>
        <td>void:entities</td>
        <td>xsd:integer</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td># of subjects</td>
        <td>void:distinctSubjects</td>
        <td>xsd:integer</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td># of properties</td>
        <td>void:properties</td>
        <td>xsd:integer</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td># of objects</td>
        <td>void:distinctObjects</td>
        <td>xsd:integer</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
	    <tr>
        <td># of classes</td>
        <td>void:classPartition</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td># of RDF graphs</td>
        <td>void:classPartition</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>SHOULD</td>
    </tr>
    <tr>
        <td>class frequency</td>
        <td>void:classPartition</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>property frequency</td>
        <td>void:propertyPartition</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>property and subject types</td>
        <td>void:propertyPartition</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
	<tr>
        <td>property and object types</td>
        <td>void:propertyPartition</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
    <tr>
        <td>property and literals</td>
        <td>void:propertyPartition</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>	
	    <tr>
        <td>property subject and object types</td>
        <td>void:propertyPartition</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
	<tr>
        <td>dataset links</td>
        <td>void:subset</td>
        <td>IRI</td>
        <td>MUST NOT</td>
        <td>MUST NOT</td>
        <td>MAY</td>
    </tr>
    </table>

    <h2 id="metadataguidancenotes">6 Metadata Guidance Notes</h2>

    <p>In this section, we discuss each of the properties to be provided for a metadata description and the expected values. To aid our discussion consider the ChEMBL dataset; the complete example is given in <a href="#appendix_1">Appendix 10.1</a>. ChEMBL is manifested in 17 different versions, of which each version can be accessed in a variety of data formats. Thus, to be fully conformant with this specification, there would be one Summary Level description that is linked to 17 Version Level descriptions, and each of the Version Level descriptions would be linked to their corresponding Distribution Level descriptions. This is captured by the following example expressed in RDF/Turtle format:</p>

    <pre>
# Summary Level Description
:chembl a dctypes:Dataset .

# Version Level Description
:chembl17 a dctypes:Dataset ;
    dct:isVersionOf :chembl;
    pav:version "17.0";
    dcat:distribution :chembl17rdf, 
    	:chembl17db .

# Distribution Level Descriptions
:chembl17rdf a dcat:Distribution, void:Dataset .
:chembl17db a dcat:Distribution .
    </pre>
    
    <p>We note that we do not expect data sources to generate descriptions for all previously published versions of a dataset due to the effort this would require, e.g. ChEBI has published over 100 versions.</p>

    <h3 id="s6_1">6.1 Literals</h3>

    <h4>6.1.1 Dates</h4>

    <p>Dates should be given as accurately as possible as an rdfs:Literal. 
    It is recommended that the value is typed as an <a href="http://www.w3.org/TR/xmlschema-2/#dateTime">xsd:dateTime</a>
    (YYYY-MM-DDThh:mm:ss[Z], where [Z] is optionally specified as Z for UTC time or provided as a time zone offset, 
    e.g. -04:00 for EDT). In the case that the time is not precisely known, we recommend using the relevant 
    <a href="http://www.w3.org/TR/NOTE-datetime">ISO 8601 Date and Time compliant string</a> typed using the 
    appropriate <a href="http://www.w3.org/TR/xmlschema-2/">XML Schema datatype</a>. For example
    </p>
    <ul>
    	<li>Only year is known: '"2013"^^xsd:gYear';</li>
    	<li>Year and month is known: '"2013-12"^^xsd:gYearMonth';</li>
    	<li>Year, month and day is known: '"2013-12-05"^^xsd:date';</li>
    	<li>Year, month, day and timestamp (with timezone): '"2013-12-05T05:32:23-05:00"^^xsd:dateTime'.</li>
    </ul>

    <h4>6.1.2 Values as Strings</h4>

    <p>Values should be stated with a language tag, unless capturing an identifier or some structured value, e.g. version identifier. Values may be captured in multiple languages.</p>

    <h4>6.1.3 Values as Strings or IRIs</h4>

    <p>For several predicates there is the choice of providing the value as an IRI or a string. We recommend that IRIs are used wherever possible.</p>

    <h3 id="s6_2">6.2 Core Metadata</h3>

    <h4>6.2.1 Dataset Identification and Declaration of Type</h4>

    <p>It is a good general practice that data represented using Semantic Web technologies be typed as an instance of some class of entities. All summary and version level descriptions are typed as dctypes:Dataset. The distribution level description can also be typed as dctypes:Dataset but needs to be additionally typed as a dcat:Distribution. RDF formatted datasets are typed as an instance of a void:Dataset.</p>

    <pre>
:chembl
    rdf:type dctypes:Dataset .

:chembl17
    rdf:type dctypes:Dataset.

:chembl17rdf
    rdf:type dctypes:Dataset, dcat:Distribution, void:Dataset .
    </pre>

    <h4>6.2.2 Title</h4>

    <p>At least one human-readable title should be provided for a dataset using dct:title. Alternative or older titles may be specified using dct:alternative.</p>

    <p>For example, to provide a title and alternative title for the ChEMBL dataset:</p>

    <pre>
:chembl
       dct:title "ChEMBL"@en ;
       dct:alternative "ChEMBLdb"@en ;
    </pre>

    <h4>6.2.3 Description</h4>

    <p>It is expected that the description will be the same as the text that appears on the web page for the dataset (see below). It should be a few paragraphs that explain to a domain expert the contents of the dataset. Where available, the description should be provided in alternative languages, each with the appropriate language tag. For instance, to specify a description for the chembl dataset:</p>

    <pre>
:chembl 
    dct:description """ChEMBL is a database of bioactive compounds, their quantitative properties and bioactivities 
        (binding constants, pharmacology and ADMET, etc). The data is abstracted and curated from the primary 
        scientific literature."""@en .
    </pre>

    <h4>6.2.4 Dates of Creation and Issuance</h4>

    <p>It is essential to know when a dataset came into existence. Within the dataset description model, the summary level description is not associated with a creation or issued date, these are associated with the version and distribution level description.</p>

    <p>Since some datasets only provide information about when they are made public, it is recommended that at least one of the creation or issued dates MUST be provided. Both MAY be provided. For versioned or distribution dataset descriptions, state the date the dataset was generated using dct:created and/or the date the dataset was made public using dct:issued. For instance, to specify that the chembl17 dataset (see <a href="#s6_2">Section 6.2</a>, <a href="#s6_3">6.3</a>, <a href="#s6_4">6.4</a> and <a href="#s6_5">6.5</a> for more details about :chembl17 declaration) was issued on 29 August 2013.</p>

    <pre>
:chembl17
    dct:issued "2013-08-29"^^xsd:date .
    </pre>

    <p>To state when a dataset (i.e. at the abstract level) was originally created, a version level description representing the first version should be provided which states the orginal creation date of the dataset.</p>

    <p>Note that other more specific properties, e.g. the date the dataset was authored or curated, MAY be given in addition using terms from the PAV ontology [<a href="#PAV">PAV</a>].</p>

    <pre>
:chembl17
    pav:createdOn "2013-08"^^xsd:gYearMonth;
    pav:authoredOn "2013-07"^^xsd:gYearMonth;
    pav:curatedOn "2013-07"^^xsd:gYearMonth;
    </pre>

    <h4>6.2.5 Authorship, Creation, Curation</h4>

    <p>Details of the individual or organisation responsible for creating a dataset MUST be provided using the dct:creator property. The value should be an IRI for the individual or organisation that can be resolved for more details. We recommend the use of ORCID ID [<a href="#ORCID">ORCID</a>] for researchers.  </p>

    <pre>
:chembl17
    dct:creator [ foaf:page &lt;https://www.ebi.ac.uk/chembl/&gt; ] .

:chembl17
    pav:authoredBy &lt;http://orcid.org/0000-0002-8011-0300&gt; .
    </pre>

    <p>If it is not possible to use an existing IRI then a string can be included using the following construct:</p>
    <pre>
:chembl17
    dct:creator [
        foaf:name "Anna Gaulton"
    ] .
    </pre>

    <p>Fine-grained attribution of creation events such as authoring or curation MAY additionally be supplied using the terms from the PAV ontology.</p>

    <ul>
    <li><strong>Authorship</strong>: State the author(s) with pav:authoredBy and linking to URIs for the authors. The date of authorship should be given using pav:authoredOn.</li>
    <li><strong>Creation</strong>: State the creator(s) with pav:createdBy and linking to URIs for the authors. The date of authorship should be given using pav:createdOn.</li>
    <li><strong>Curation</strong>: State the author(s) with pav:curatedBy and linking to URIs for the authors. The date of authorship should be given using pav:curatedOn.</li>
    </ul>

    <pre>
:chembl17
    pav:authoredBy [
        foaf:name "Anna Gaulton"
    ] .
    </pre>

    <h4>6.2.6 Publisher</h4>

    <p>A link to the entity – viz the person, organisation, or service – responsible for publishing the dataset.</p>

    <pre>
:chembl
    dct:publisher [ foaf:page &lt;http://www.ebi.ac.uk&gt; ] .
    </pre>

    <p>Note that there is not a URI for the EBI. To avoid confusion between the organisation and their webpage we make use of a blank node.</p>

    <h4>6.2.7 Webpage and Logo</h4>

    <p>A link to the human-oriented web page for the dataset should be provided using the foaf:page property [<a href="#FOAF">FOAF</a>]. The property foaf:homepage must not be used as it could result in the data about different versions of a dataset being combined as it is an inverse-functional property. The example below specifies the chembl dataset is accessible at [<a href="#ChEMBL">ChEMBL</a>].</p>
    <p>A link to an image file containing the logo for the dataset should be provided using the schemaorg:logo property [<a href="#SCHEMAORG">SCHEMA.ORG</a>]. The property foaf:logo must not be used since it is an inverse-function property.</p>

    <pre>
:chembl
    foaf:page &lt;http://www.ebi.ac.uk/chembl/&gt; ;
    schemaorg:logo &lt;http://www.ebi.ac.uk/rdf/sites/ebi.ac.uk.rdf/files/resize/images/rdf/chembl_service_logo-146x48.gif&gt; .
    </pre>

    <h4>6.2.8 Keywords</h4>

    <p>Keywords and topics of coverage of the dataset MAY be given. It is recommended that such terms are drawn from a suitable domain vocabulary and declared using the dcat:theme predicate. The dcat:keyword predicate is provided for the rare occasions where there is not a suitable term in a vocabulary.</p>

    <pre>
@prefix ncit: &lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#&gt; .

:chembl 
    dcat:theme ncit:C48807 ; # chemical
    dcat:keyword "chemical"^^xsd:string, "assay"^^xsd:string .
    </pre>

    <p>Note that the ncit namespace refers to the National Cancer Institute (NCI) Thesaurus.</p>

    <h4>6.2.9 Licensing and Rights</h4>


    <p>The license under which the data is published MAY be stated at the summary level, SHOULD be stated at the version level, and MUST be stated and the distribution level. A dataset MAY have one or more licenses, although the provider should ensure that multiple licenses are consistent with each other. The object of the license predicate is the URI of the license. In cases where this is not know, but the dataset version and distribution are available, the following use of a blank node should be used to state that the license is unknown. Any details of a possible point of contact for the license can be given in the comment. We note that this modelling requires human intervention, but since the license is unknown this is appropriate.</p>

    <pre>
&lt;http://example.com&gt; dct:license [ rdfs:comment "License unknown".]
    </pre>

    <p>The details of the license may be summarised in a rights statement.</p>

    <pre>
:chembl17
    dct:license &lt;http://creativecommons.org/licenses/by-sa/3.0/&gt; .
    dct:rights """The data in ChEMBL is covered by the Creative Commons By Attribution. Under the -BY clause, we request attribution for subsequent use of ChEMBL.  For publications using ChEMBL data, the primary current citation is:

1.  A. Gaulton, L. Bellis, J. Chambers, M. Davies, A. Hersey, Y. Light, S. McGlinchey, R. Akhtar, A.P. Bento, B. Al-Lazikani, D. Michalovich, &amp; J.P. Overington (2012) 'ChEMBL: A Large-scale Bioactivity Database For Chemical Biology and Drug Discovery' Nucl. Acids Res. Database Issue. 40 D1100-1107 DOI:10.1093/nar/gkr777 PMID:21948594

If ChEMBL is incorporated into other works, we ask that the ChEMBL IDs are preserved, and that the release number of ChEMBL is clearly displayed."""
    </pre>

    <h4>6.2.10 Language</h4>

    <p>Declare the languages the data is published in using dct:language and values taken from the Lexvo.org Ontology [<a href="#Lexvo">Lexvo</a>].</p>

    <pre>
:chembl17
    dct:language &lt;http://lexvo.org/id/iso639-3/eng&gt; .
    </pre>

    <h4>6.2.11 References</h4>

    <p>Supporting material including web pages and documents MAY be added using the dct:references property. We recommend the use of CiTO [<a href="#CiTO">CiTO</a>]'s cito:citesAsAuthority property to specifically link to publications about the dataset. CiTO also provides a wide range of other properties for capturing other aspects of the relationship between the dataset description and the publication. For example, for the :chembl dataset the literature reference is [<a href="#Gaultonetal2011">Gaulton et al 2011</a>].</p>
	<p>Other related materials MAY be added using rdfs:seeAlso. For instance, we can include a reference to the ChEMBL Wikipedia page.</p>


    <pre>
:chembl
    cito:citesAsAuthority &lt;http://nar.oxfordjournals.org/content/40/D1/D1100&gt; ;
    rdfs:seeAlso &lt;http://en.wikipedia.org/wiki/ChEMBL&gt; .
    </pre>

    <h4>6.2.12 Vocabularies</h4>

    <p>RDF datasets use one or more RDFS vocabularies or OWL ontologies to represent the data. It is recommended that the distribution level metadata, for RDF datasets, should state what terminologies were used in the dataset using void:vocabulary [<a href="#VOID">VOID</a>]. The value has to be a URI identifying the terminology used.</p>

    <pre>
:chembl17rdf
    void:vocabulary &lt;http://rdf.ebi.ac.uk/terms/chembl#&gt;, &lt;http://www.w3.org/ns/dcat#&gt;, &lt;http://purl.org/dc/terms/&gt; .
    </pre>

    <h4>6.2.13 Conformance</h4>

    <p>Indicate that the dataset conforms to a particular format or standard using the dct:conformsTo property, which MUST NOT be represented at the summary level, MAY be represented at the version, and SHOULD be represented at the distribution level. For example, the follow states that the ChEMBL version 17 description conforms to this specification.</p>

    <pre>
:chembl17
    dct:conformsTo &lt;http://www.w3.org/2001/sw/hcls/notes/hcls-dataset/&gt; .
    </pre>

    <h4>6.2.14 Subsets</h4>

    <p>The parts of a dataset MAY be described using dct:hasPart. For example, ChEMBL identifies several datasets, e.g. one containing data about molecules and another about targets. Each of these subsets can be assigned appropriate topics.</p>

    <pre>
:chembl17
    dct:hasPart :chembl17_rdf_molecule_dataset, :chembl17_rdf_target_dataset .
    </pre>

    <h3 id="s6_3">6.3 Identifiers</h3>

    <h4>6.3.1 Preferred and Alternative Prefixes</h4>

    <p>A preferred prefix is a short label that is commonly used to refer to the dataset. Such a label may stand in place of the base IRI of the dataset (e.g. see <a href="http://prefix.cc">http://prefix.cc</a>). Preferred short names should be specified using idot:preferredPrefix while alternate short names should be specified using idot:alternatePrefix. These properties may be used at any description level.</p>

    <pre>
:chembl
    idot:preferredPrefix "chembl";
    idot:alternatePrefix "chembldb" .
    </pre>

    <h4>6.3.2 Identifier, Resource, and Access Patterns</h4>

    <p>The idot:identifierPattern MAY be provided for distribution level descriptions, where it provides a regular expression for alphanumeric strings used to identify items or records in the dataset.</p>

    <pre>
:chembl17rdf
    idot:identifierPattern "CHEMBL\\d+"^^xsd:string .
    </pre>

    <p>The void:uriRegexPattern property MAY be provided for distribution level descriptions, where it provides a regular expression whose transitive closure denotes a superset of data item URIs in the dataset.</p>

    <pre>
:chembl17rdf
    void:uriRegexPattern "http://rdf.ebi.ac.uk/resource/chembl/target/CHEMBL\\d+" .
    </pre>

    <p>The idot:accessPattern MAY be used to specify how to access specific formats of the resources. The access pattern is a base URI upon which the resource identifier is appended in order to generate a valid resource URL. For example, given the identifier CHEMBL25 and an access pattern &lt;http://www.ebi.ac.uk/chembl/compound/inspect/&gt;, then the valid URL would be &lt;http://www.ebi.ac.uk/chembl/compound/inspect/CHEMBL25&gt; To specify that the access pattern is for the primary data provider, set idot:primarySource to true. This can be specified for the most current version, a specific version, or a specific distribution.</p>

    <pre>
:chembl17rdf
    idot:accessPattern
        &lt;http://www.ebi.ac.uk/chembl/compound/inspect/&gt; ,
        &lt;http://identifiers.org/chembl.compound/&gt; ,
        &lt;http://bio2rdf.org/chembl:&gt; ,
        &lt;http://linkedchemistry.info/chembl/chemblid&gt; .

&lt;http://www.ebi.ac.uk/chembl/compound/inspect/&gt;
    idot:primarySource true ;
    dct:format "text/html" ;
    dct:publisher &lt;http://www.ebi.ac.uk&gt; ;
    a idot:AccessPattern .

&lt;http://identifiers.org/chembl.compound/&gt;
    dct:format "text/html" ;
    a idot:AccessPattern .

&lt;http://bio2rdf.org/chembl:&gt;
    dct:format "application/rdf+xml" ;
    dct:publisher &lt;http://bio2rdf.org&gt; ;
    a idot:AccessPattern .

&lt;http://linkedchemistry.info/chembl/chemblid&gt;
    dct:format "application/rdf+xml" ;
    a idot:AccessPattern .
    </pre>

    <h4>6.3.3 Example Identifier and Resource</h4>

    <p>An example identifier SHOULD be provided using the idot:exampleIdentifier for distribution level descriptions.</p>

    <pre>
:chembl17db
    idot:exampleIdentifier "CHEMBL25"^^xsd:string .
    </pre>

    <p>An example resource SHOULD be provided using the void:exampleResource property for distribution level description of RDF datasets.</p>

    <pre>
:chembl17rdf
    void:exampleResource &lt;http://rdf.ebi.ac.uk/resource/chembl/compound/CHEMBL25&gt; .
    </pre>

    <h3 id="s6_4">6.4 Provenance and Change</h3>

    <h4>6.4.1 Versioning</h4>

    <p>A version level description MUST use the dct:isVersionOf property to relate to the summary level description. The versions of the summary level resource may then be inferred due to the declared inverse property dct:hasVersion.</p>

    <pre>
:chembl17 
    dct:isVersionOf :chembl .
    </pre>

    <p>For each version level description, the version identifier should be declared using pav:version and restrict its value to an xsd:string. For instance, to specify that :chembl17 has a version number of "17":</p>

    <pre>
:chembl17
    pav:version "17"^^xsd:string .
    </pre>

    <p>A link to the previous version of the dataset SHOULD be provided using pav:previousVersion. This creates a chain of links through the versions of the dataset. For instance, to state that :chembl16 is a prior version of :chembl17, the following triple should be created:</p>

    <pre>
:chembl17
    pav:previousVersion :chembl16 .
    </pre>

    <p>Data publishers MAY use pav:hasCurrentVersion to declare the current version of the dataset, <strong>provided they are the authoritative source</strong> of the data and the summary level description is always made current. Data aggregators are advised to maintain the most current summary level description so that only a single such reference appears.</p>

    <pre>
:chembl
    pav:hasCurrentVersion :chembl17 .
    </pre>

    <h4>6.4.2 Dataset Provenance</h4>

    <p>A version level description of a dataset SHOULD identify the datasets used to create the published data. Use dct:source when the source dataset was used in whole or in part. Use pav:retrievedFrom when the source dataset was used in whole and was not modified from its original distribution. Use prov:wasDerivedFrom when the source dataset was in whole or in part and was modified from its original distribution.</p>

    <pre>
:chembl17
    dct:source :pubchem-bioassay-09-01-2014 ;
    pav:retrievedFrom :pubchem-bioassay-09-01-2014 ;
    prov:wasDerivedFrom :pubchem-bioassay-09-01-2014 .
    </pre>

    <p>A distribution level description of a dataset MAY describe a tool used to create the dataset (where appropriate). Details of the specific version of the tool used should be given, either as a versioned URI (e.g. from a GitHub commit) or by providing human interpretable values on a blank node. This information is useful for debugging automatic generation of the dataset. The property to be used for this purpose is: pav:createdWith, which ideally includes a reference to the version of the tool used to create the dataset.</p>

    <pre>
:chembl17rdf
    pav:createdWith :chembl-sql2rdf-exporter-v1 .
    </pre>

    <h4>6.4.3 Entity Provenance</h4>

    <p>Each data item MAY be linked to the dataset using the sio:has-data-item property. It MAY be used with distribution level descriptions of RDF distributions that are typed as void:Dataset, and MUST NOT be used for summary level descriptions or version level descriptions. In contrast, void:inDataset MAY be used to link an entity with a Document that contains it.</p>

    <pre>
:chembl17rdf
    sio:has-data-item &lt;http://rdf.ebi.ac.uk/resource/chembl/compound/CHEMBL25&gt; .
    </pre>

    <h4>6.4.4 Change Frequency</h4>

    <p>The update frequency of the dataset SHOULD be specified using dct:accrualPeriodicity with a value from the Dublin Core Frequency vocabulary [<a href="#DCFreq">DCFreq</a>]. This description appears at summary level.</p>

    <pre>
:chembl
    dct:accrualPeriodicity freq:quarterly .
    </pre>
    
    <p>Note that the change frequency is an indication of the update interval, not a contractual obligation.</p>

    <h4>6.4.5 Modifications</h4>

    <p>It is recommended that modifications are NOT made to a dataset without changing its version information. If changes are required, a new version with its own description MUST be published, and the previous version information SHOULD be maintained with a link back to it from the version that superseded it.</p>

    <pre>
:chembl17-1
    pav:previousVersion :chembl17 .
    </pre>

    <h3 id="s6_5">6.5 Availability and Distributions</h3>

    <h4>6.5.1 Distributions and Formats</h4>

    <p>Each version level description SHOULD link to the distribution level descriptions that represent the files in different data formats. Each distribution level MUST state the file format in which the data is available. This SHOULD be stated as a IANA code [<a href="#IANA-MT">IANA-MT</a>] otherwise dct:format should be used with different values (e.g. a URI from a controlled vocabulary).</p>

    <p>In the case of RDF distributions, the distribution level description should be additionally typed as void:Dataset.</p>

    <pre>
:chembl17
    dcat:distribution :chembl17rdf, :chembl17db .

:chembl17rdf
    a dctypes:Dataset, dcat:Distribution, void:Dataset ;
    dct:format "text/turtle" ;
    dct:format &lt;http://www.w3.org/ns/formats/Turtle&gt; ;
    dct:format "application/gzip" .

:chembl17db
    a dctypes:Dataset, dcat:Distribution ;
    dct:format "application/sql" .
    </pre>

    <h4>6.5.2 File Locations</h4>

    <p>It is recommended to use dcat:downloadURL to declare the distribution file in conjunction with dcat:byteSize to declare the size of the file. For RDF resources, the files should be declared using void:dataDump. Use dcat:accessURL to specify a directory containing the file(s) of interest.</p>

    <pre>
# Summary level declaration
:chembl
    dcat:accessURL &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb&gt; .

# Version level declaration
:chembl17
    dcat:accessURL &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_17/&gt; .

# Distribution level declaration
:chembl17sql
    dcat:downloadURL &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_17/chembl_17_mysql.tar.gz&gt; ;
    dcat:byteSize "861443887"^^xsd:decimal .

:chembl17rdf
    void:dataDump &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBL-RDF/17/chembl_17_molecule.ttl.gz&gt; .
    </pre>

    <h4>6.5.3 Query Endpoint</h4>

    <p>Publishers may also provide their data through a SPARQL endpoint. We recommend that such an endpoint should have a service description [<a href="#SD">SD</a>] and this should link to the distribution level description that is currently loaded (see Figure 1).</p>

    <p>SPARQL endpoints may optinally follow <a href="http://www.w3.org/TR/void/#deploying">VOID deployment guidelines</a>.</p>

    <p>Below is an example based on the one given in <a href="http://www.w3.org/TR/2011/NOTE-void-20110303/#sparql-sd">Section 6.5</a> of the VOID guidelines [<a href="#VOID">VOID</a>] to indicate how this may be achieved for the default graph of a triplestore.</p>

    <pre>
:service
    a sd:Service ;
    sd:defaultDatasetDescription [
        a sd:Dataset ;
        sd:defaultGraph [
            a sd:Graph ;
            dct:source :chembl17rdf ;
        ] ;
    ] .
    </pre>

    <p>Note that once the file is loaded into the triplestore it becomes a different representation of the same dataset version. Hence the use dct:source rather than directly linking to the dataset description file.</p>

    <p>We recommend that the void:sparqlEndpoint SHOULD be used at the summary level. However, we recommend that this property SHOULD NOT be used at the version and/or distribution level, unless there is a commitment to specifically provide that content in the specified endpoint.</p>

    <h4>6.5.4 Dataset Documentation</h4>

    <p>Details of documentation associated with a dataset – either for the dataset itself or a web service through which it is made available – can be given using the dcat:landingPage predicate.</p>

    <pre>
:chembl17
    dcat:landingPage &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_17/chembl_17_release_notes.txt&gt; .
    </pre>

    <h3 id="s6_6">6.6 Statistics</h3>

    <p>Dataset statistics offer one means by which to understand the contents of the dataset and their relation to other datasets. Below we provide recommendations for the capture of dataset statistics for RDF formatted files using the VoID vocabulary. These statistics can be computed on an RDF dataset using the provided SPARQL queries [<a href="#VOID-SPARQL">VOID-SPARQL</a>]. The results of the SPARQL queries can be added to the description of the RDF-formatted dataset.</p>

    <h4>6.6.1 Core statistics</h4>

    <p>Core statistics provide basic information about datasets, such as the total number of triples in the dataset, number of unique entities (subject URIs), etc., as well as information about the number of unique classes, literals, and graphs in a dataset. We use <a href="http://www.w3.org/TR/void/">VoID</a> and <a href="http://ldf.fi/void-ext">extensions</a> as a vocabulary to specify the datasets statistics. Exemplar SPARQL queries are included. Additional SPARQL queries can be found at <a href="https://code.google.com/p/void-impl/wiki/SPARQLQueriesForStatistics">VoID-impl</a> and <a href="https://gist.github.com/yayamamo/8052bd4620c1c58adff8">here</a>.</p>

    <h5>6.6.1.1 To specify the <strong>number of triples</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:triples "###"^^xsd:integer .
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT (COUNT(*) AS ?triples) 
{ ?s ?p ?o  }
    </pre>

    <h5>6.6.1.2 To specify the <strong>number of unique, typed entities</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:entities "###"^^xsd:integer .
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT (COUNT(DISTINCT ?s) AS ?entities)
{ ?s a [] }
    </pre>

	
    <h5>6.6.1.3 To specify the <strong>number of unique subjects</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:distinctSubjects "###"^^xsd:integer .
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT (COUNT(DISTINCT ?s) AS ?distinctSubjects) 
{  ?s ?p ?o   }
    </pre>

    <h5>6.6.1.4 To specify the <strong>number of unique properties</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:properties "###"^^xsd:integer .
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT (COUNT(DISTINCT ?p) AS ?distinctProperties)
{ ?s ?p ?o }
    </pre>

    <h5>6.6.1.5 To specify the <strong>number of unique objects</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:distinctObjects "###"^^xsd:integer .
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT (COUNT(DISTINCT ?o ) AS ?distinctObjects) 
{  ?s ?p ?o  FILTER(!isLiteral(?o)) }
    </pre>

    <h5>6.6.1.6 To specify the <strong>number of unique classes</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:classPartition [
		void:class rdfs:Class ;
		void:distinctSubjects "###"^^xsd:integer
	] .
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT (COUNT(DISTINCT ?o) AS ?distinctClasses)
{ ?s a ?o }
    </pre>

     <h5>6.6.1.7 To specify the <strong>number of unique literals</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:classPartition [
		void:class rdfs:Literal ;
		void:distinctSubjects "###"^^xsd:integer
	] .
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT (COUNT(DISTINCT ?o) AS ?distinctLiterals) 
{  ?s ?p ?o  filter(isLiteral(?o)) }
    </pre>

    <h5>6.6.1.8 To specify the <strong>number of graphs</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:classPartition [
		void:class sd:Graph ;
		void:distinctSubjects "###"^^xsd:integer
	].
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT (COUNT(DISTINCT ?g ) AS ?graphs) 
{ GRAPH ?g { ?s ?p ?o }}
    </pre>

    <h4>6.6.2 Enhanced Statistics</h4>

    <p>Enhanced statistics provide in-depth details that are not captured by basic statistics. These record the number of instances per class and multiple counts about properties. The enhanced statistics give an overview of the utilization of data within the dataset and to other datasets as linked data. We strongly recommend the inclusion of a human readable label (using rdfs:label) on an identified class or property.
</p>

   <h5>6.6.2.1 To specify the <strong>classes and the number of their instances</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:classPartition [
		void:class &lt;class-uri&gt; ;
		void:distinctSubjects "###"^^xsd:integer
	] .
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT ?o (COUNT(DISTINCT ?s) AS ?distinctInstances) 
{ ?s a ?o } 
GROUP BY ?o
    </pre>

    <h5>6.6.2.2 To specify the <strong>properties and their occurrence</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:propertyPartition [
		void:property &lt;property-uri&gt; ;
		void:triples "###"^^xsd:integer
	] .
    </pre>

    <p>SPARQL query:</p>

    <pre>
SELECT ?p (COUNT(?p) AS ?triples) 
{ ?s ?p ?o } 
GROUP BY ?p
    </pre>
	
	<h5>6.6.2.3 To specify the <strong>property, the number of unique typed subjects, and number of triples linked to a property</strong> in the dataset:</h5>
    <pre>
:rdfdataset
	void:propertyPartition [
		void:property &lt;property-uri&gt; ;
		void:triples "###"^^xsd:integer ;
		void:classPartition [
			void:class &lt;subject-class-uri&gt; ;
			void:distinctSubjects "###"^^xsd:integer ;
	]].
    </pre>
    <p>SPARQL query:</p>
    <pre>
SELECT (COUNT(DISTINCT ?s) AS ?scount) ?stype ?p (COUNT(?p) AS ?triples) 
{ 
 ?s ?p ?o . 
 ?s a ?stype 
} GROUP BY ?p ?stype
    </pre>

	
	<h5>6.6.2.4 To specify the <strong>number of unique typed objects linked to a property</strong> in the dataset:</h5>
    <pre>
:rdfdataset
	void:propertyPartition [
		void:property &lt;property-uri&gt; ;
		void:triples "###"^^xsd:integer ;		
		void-ext:objectClassPartition [
			void:class &lt;object-class-uri&gt; ;
			void:distinctObjects "###"^^xsd:integer
	]].
    </pre>
    <p>SPARQL query:</p>
    <pre>
SELECT ?p (COUNT(?p) AS ?triples) ?otype (COUNT(DISTINCT ?o) AS ?ocount) 
{ 
 ?s ?p ?o . 
 ?o a ?otype .
} GROUP BY ?p ?otype
    </pre>

    <h5>6.6.2.5 To specify the <strong>triples and number of unique literals that are related to a property</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:propertyPartition [
		void:property &lt;property-uri&gt; ;
		void:triples "###"^^xsd:integer ;
		void-ext:objectClassPartition [
			void:class rdfs:Literal;
			void:distinctObjects "###"^^xsd:integer
	]] .
    </pre>
    <p>SPARQL query:</p>
    <pre>
SELECT ?p (COUNT(?p) AS ?triples) (COUNT(DISTINCT ?o) AS ?distinctLiterals) 
{ 
 ?s ?p ?o . 
 FILTER (isLiteral(?o))
} GROUP BY ?p 
    </pre>

	
    <h5>6.6.2.6 To specify the number of <strong>unique subject types that are linked to unique object types</strong> in the dataset:</h5>

    <pre>
:rdfdataset
	void:propertyPartition [
		void:property &lt;property-uri&gt; ;
		void:classPartition [
			void:class &lt;subject-class-uri&gt; ;
			void:distinctSubjects "###"^^xsd:integer ;
		];
		void-ext:objectClassPartition [
			void:class &lt;object-class-uri&gt; ;
			void:distinctObjects "###"^^xsd:integer ;
		];
	] .
    </pre>
    <p>SPARQL query:</p>
    <pre>
SELECT (COUNT(DISTINCT ?s) AS ?scount) ?stype ?p ?otype  (COUNT(DISTINCT ?o) AS ?ocount)  
{ 
 ?s ?p ?o . 
 ?s a ?stype .
 ?o a ?otype .
} GROUP BY ?p ?stype ?otype
    </pre>

	

   <h5>6.6.2.7 To specify the <strong>number and list of properties that link items from one dataset to another</strong>:</h5>

    <pre>
:rdfdataset
    void:subset [
        a void:LinkSet ;
        void:linkPredicate &lt;property-uri&gt; ;
        void:subjectsTarget &lt;subject-dataset-uri&gt; ; 
        void:objectsTarget &lt;object-dataset-uri&gt; ;
        void:triples "###"^^xsd:integer
    ] .
    </pre>

  <h2 id="usageNotes">7 Using Dataset Descriptions</h2>
    <h3 id="s7n_1">7.1 Workflows</h3>

<p>A common usecase for dataset usage and creation is within workflows.  The above sections have detailed the
what and where of dataset description.  This section will briefly describe the contex of how a dataset might be
consumed or produced within a workflow definition.  A more complete description is outside the scope of this 
note.</p>

    <h4>7.1.1 General Workflows</h4>

<p>Both PROV [<a href="#PROV">PROV</a>] and PAV [<a href="#PAV">PAV</a>] ontologies provide terms for describing 
how the provenance of a workflow that dataset(s) are a part of can be captured, much of which is captured in the 
sections above.  Using PROV, the basic template is that the dataset itself is described following the recommendation 
of this note, with the following addition considerations.  A dataset description MAY be referenced as appropriate in 
the workflow triples as an input</p>
    <pre>
:workflow a prov:Activity
:chembl17rdf a prov:Entity

:workflow prov:used :chembl17rdf .
    </pre>
<p>and/or as an output</p> 
    <pre>
:workflow a prov:Activity
:chembl17rdf a prov:Entity

:chembl17rdf prov:wasGeneratedBy :workflow .
#    or
:chembl17rdf prov:wasDerivedFrom :workflow .
# or one of prov:wasDerivedFrom three property subclasses: prov:wasQuotedFrom; prov:wasRevisionOf; or prov:hadPrimarySource
    </pre>
<p>The dataset MAY be associated with persons, software, or organizations from both PROV and PAV.  The VIVO 
[<a href="#PAV">VIVO</a>] ontology MAY also provide more fine-grained terms for describing people and organizations</p>
    <pre>
:simon a prov:Agent;
       a prov:Person .

:chembl17rdf prov:wasAttributedTo :simon .
:chembl17rdf pav:createdBy :simon .
    </pre>

    <h4>7.1.2 Computational Workflows</h4>

<p>One MAY also use terms from the PROV derived ontologies, wfprov and wfdesc [<a href="#wf4ever">wf4ever</a>] or the 
OPMW ontology [<a href="#OPMW">OPMW</a>] which derives from both PROV and OPM [<a href="#OPM">OPM</a>] to 
describe more computational based workflows.  These ontologies provide the ability to capture abstract workflows that 
workflow runs can use as a plan and provide finer grained terms for specifying parameters, where dataset generation MAY 
be associated with parameters.  The Taverna project provides a model for capturing their workflows as PROV 
[<a href="#TavernaProvenance">TavernaProvenance</a>] using wfprov and wfdesc along with their extension 
tavernaprov [<a href="#TavernaProv">TavernaProv</a>].</p>

    
<p>Extending this using terms from wfprov and wfdesc, the version description of a Dataset MAY 
be used in the Workflow description as input or output</p>
    <pre>
:workflow a wfdesc:WorkflowInstance .
:process a wfdesc:Process .
:input a wfdesc:Input .
:output a wfdesc:Output .
:chembl17 a wfdesc:Artifact .

:workflow wfdesc:hasSubProcess :process .
:process wfdesc:hasInput :input .
:process wfdesc:hasOutput :output .
:input wfdesc:hasArtifact :chembl17 .
:output wfdesc:hasArtifact :chembl17 .
    </pre>

<p>In a corresponding run for this WorkflowInstance, the distributed description of the Dataset MAY be used</p>
    <pre>
:run a wfprov:WorkflowRun .
:processRun a wfprov:ProcessRun .
:chembl17rdf a wfprov:Artifact .
:chembl17sql a wfprov:Artifact .

:run wfprov:descrbedByWorkflow :workflow .
:processRun wfprov:describedByProcess :process ;
            wfProv:usedInput :chembl17rdf .
:chembl17rdf wfprov:describedByParameter :input .
:chembl17sql wfprov:describedByParameter :output ;
             wfProv:outputFrom :processRun .
    </pre> 

    <h2 id="toolingsupport">8 Tooling Support</h2>

    <p>A list of tools to help support dataset descriptions, e.g. editors for their creation or validators for checking their consistency with the specification, is being maintained on the <a href="https://www.w3.org/wiki/HCLSIG/Tools">HCLS Wiki</a>.</a></p>
<!--
    <p>To support the provision of dataset descriptions conforming with this specification, two tools have been provided.</p>

    <h3 id="s7_1">8.1 Dataset Description Generation Tool</h3>

    <p>The <a href="http://voideditor.cs.man.ac.uk/">dataset generator</a> helps with the creation of initial drafts of dataset descriptions. It is anticipated that the dataset description will be created as part of the same process that generates the data, i.e. they are part the same (automated) production workflow, and the template generated by the tool can be used in a production pipeline.</p>

    <p>Note that the current tool is for the creation of datasets conforming to the closely related <a href="http://www.openphacts.org/specs/datadesc/">Open PHACTS dataset description guidelines</a>. This will be updated.</p>

    <h3 id="s7_2">8.2 Validation Tool</h3>

    <p>The <a href="http://www.macs.hw.ac.uk/~ajg33/HCLSValidator/">validator</a> is a tool that checks a dataset description against this specification. Validation can be at different levels of conformance:</p>

    <ol>
    <li>Minimal: all MUST properties have been provided. Datasets conforming to this minimal version of the specification can be branded with the following logo.</li>
    <li>Strict: all MUST and some SHOULD properties have been provided but no additional properties have been given.</li>
    <li>Recommended: all MUST properties have been supplied together with SHOULD and MAY properties. Datasets conforming to this specification can be branded with the following logo.</li>
    </ol>

    <p>Currently, the validator requires the whole dataset description to be pasted into a web form. It is anticipated that an API will be provided.</p>
-->
    <h2 id="usecases">9 Use Cases</h2>

    <h3 id="s8_1">9.1 Marshfield Use Case</h3>

    <p>Marshfield Clinic is one of the largest physician group practices in the United States, who employs approximately 780 physicians representing 84 different specialities and 6,500 additional staff working on the main campus in Marshfield or one of 52 regional clinics serving the population of Wisconsin and the upper peninsula of Michigan. Integral to clinical practice, Marshfield Clinic Research Foundation (MCRF) conducts clinical and biomedical research projects.</p>

    <p>Marshfield is a member of the Health Maintenance Organization Research Network (HMORN). To enable population-based health and health care research across 16 members in HMORN, Marshfield participates in a standardized federated data system called Virtual Data Warehouse (VDW). VDW enables the query to be distributed to different sites. The query result from each site is summarized at each site and then combined to be returned to the requester. In such a scenario, a description of the original query, the database that was queried, and a description of the query results would be useful for keeping track of the provenance of the query results. Useful metadata include human readable titles, detailed descriptions, a list of individuals responsible, date and times for when the database was compiled, the query was issued, the results obtained, as well as licensing for the database and results, keywords describing the database, the format of the query and results, and the version of the database.</p>

    <p>Marshfield also participates in a clinical pharmacogenomics consortium called eMERGE-PGx. A goal of eMERGE-PGx is to discover novel associations between genotypes and pharmacogenomics responses. The more data accumulated from different participating sites, the higher the statistical power to detect novel associations. Standardized metadata description, especially descriptors of license conditions and rights, will ensure transparencies in genetic research and data sharing. With proper metadata available for each data set, pharmacogenomics discovery can be made by agent-based algorithms and proper reuse of data.</p>

    <h3 id="s8_2">9.2 Metaome Transcriptomics Use Case</h3>

    <p>Gene expression data analysis has emerged as a powerful approach for understanding biology. RNA-seq, microarrays and qPCRs are some of the common approaches for analyzing gene expression. To understand gene function, it is often necessary to analyze gene expression over various experimental conditions. It is important that, from a large corpus of transcriptomics datasets, users are able to retrieve datasets that match specific experimental criteria. Further, based on the experiment metadata, the datasets can be enriched with relevant information such as related mutations, cell lines and phenotypes.</p>

    <p>A well-structured and standardized dataset description is imperative for this operation. Such an approach of slicing large corpus of transcriptomics data, based on biological parameters and experimental conditions is recognized by our customers as a strong base for gene expression analytics. A structured approach to describing datasets combined with gene expression analytics could lead to applications such as better classification of tumor samples and drug-repurposing.</p>

    <h3 id="s8_3">9.3 Radiotherapy Research Use Case</h3>

    <p>MAASTRO Clinic is a radiotherapy clinic with approximately 200 employees and 60 researchers. Several use case scenarios at MAASTRO make use of distributed heterogeneous data, where data discovery plays a critical role.</p>

    <p>The first use case scenario involves a MAASTRO researcher wants to perform a retrospective study using previously collected routine clinical care data. Often, the necessary data is spread across several databases and data sources, requiring knowledge of several data schemas and interfaces in order to retrieve data. Ideally, a Research Data Archive (RDA) would present a single access point for researchers to find many types of data for their research including: patient demographic data, treatment and planning data such as CT images, tumor volume, dose, and fractionation (i.e. doses divided across 'fractions'). The RDA is being built from a combination of a data warehouse and SPARQL federation and will contain a catalogue of all data sources, some of which will be data that has been analyzed in specific publications. In cases where data has been calculated by a program, the data should include provenance such as the program and version which was used to generate it. A self-maintaining catalogue (i.e. dynamically generated from dataset descriptions) would help to keep the RDA manageable as it grows to a larger scale, as well as lower the cost of adding data sources and maintenance of tools for data access.</p>

    <p>In projects such as <a href="http://www.eurocat.info/">euroCAT</a> and <a href="http://eurecaproject.eu/">EURECA</a>, MAASTRO needs to facilitate data sharing with external partners. In EuroCAT, a system for machine learning has been built up based on a principle of a uniform data interface that enables machine learning algorithms to 'visit' data at the hospital and clinic. This circumvents the security and legal problems that arise when sending clinical data outside the walls of the hospital. In this case, each hospital could use dataset descriptions to make data discovery possible for other partners. The same principle can be applied to biobanks.</p>

    <p>In the EURECA project, a legal and technical framework has been created that enables clinical care and clinical research data to be shared via a Center for Data Protection (CDP). However, as the data collection grows, it becomes steadily more difficult to find data based on attributes of interest. Therefore, a standardized dataset description will enable project partners to make better use of the data by enabling data discovery.</p>

    <h3 id="s8_4">9.4 Computational Network Biology</h3>

    <h4>9.4.1 Biological Network Data Users</h4>

    <p>The Cytoscape software for network visualization and analysis [<a href="#Cytoscape">Cytoscape</a>] and the GeneMANIA software for gene function prediction (http://genemania.org/) depend on loading biological network and related data from numerous and diverse sources to support various types of analysis. Cytoscape is a stand alone workbench application and data loading is driven by users and GeneMANIA primarily accesses data using an automated build process. Both systems will benefit from knowledge of the following aspects of a data set:</p>

    <ul>
    <li>license - generally needed to support commercial users who need to separate commercial from open data</li>
    <li>data source short name (for GUI display purposes), full name (may go in a tooltip) and description</li>
    <li>homepage URL, PMIDs (find out more information about the data set/data source)</li>
    <li>example data URL - useful to help browse contents of an online data source, e.g. an example pathway database record</li>
    <li>production date - needed to communicate to users about how current the data is</li>
    <li>download date - needed to communicate to users about how current the data is</li>
    <li>version - needed to communicate to users about how current the data is</li>
    <li>update cycle - frequency of update, useful for build systems to figure out how often to check for data updates</li>
    <li>dataset statistics. Useful to gauge the overall size of the data. Ideally this would be the number of genes/protein/molecules and the number of interactions, broken down into type of interaction would be even better</li>
    </ul>

    <p>For GeneMANIA, to fully automate discovery of new data sets (a true intelligent agent), we would need to know the data type (e.g. protein-protein interaction, text mined co-citations, pathways, gene expression), the organism, the types of gene identifiers and the number of genes covered by a given number of interactions.</p>

    <p>For Cytoscape, most users would also be interested to know how others have used the data, as otherwise, they would not know what to do with the list of data sets (at least if there was no further categorization).</p>

    <h4>9.4.2 Pathway Commons and Pathguide.org</h4>

    <p>The goal of Pathway Commons (http://www.pathwaycommons.org/about/) is to collect all publicly available biological pathway information and make it easily and widely available. Pathguide (http://www.pathguide.org/) tracks over 540 databases containing pathway related information. This tracking website is currently manually updated, but it would be great if it could be automatically updated by downloading metadata files from each database. In addition to the above metadata useful for GeneMANIA and Cytoscape, the nature of the data source in terms of originality is important for Pathway Commons, as originally curated information is desired, not redundant copies of data from meta-databases. Pathguide terms this &ldquo;primary&rdquo; (originally curated or predicted) or &ldquo;secondary&rdquo; (collected from other sources). An example Pathguide record for GeneMANIA is at
    <a href="http://pathguide.org/fullrecord.php?organisms=all&amp;availability=all&amp;standards=all&amp;order=alphabetic&amp;DBID=334">http://pathguide.org/fullrecord.php?organisms=all&amp;availability=all&amp;standards=all&amp;order=alphabetic&amp;DBID=334</a>.</p>

    <h3 id="s8_5">9.5 Safety Information Evaluation and Visual Exploration ("SIEVE")</h3>

    <p>AstraZeneca ("AZ") Patient Safety Science wanted to improve retrieval of clinical trial data and biometric assessments across studies.  Traditionally, evaluation of clinical trials data across studies required manual intervention to deliver desired datasets.   A proposal titled Safety Information Evaluation and Visual Exploration ("SIEVE") was sponsored by Patient Safety Science.  This took the form of collaboration between AZ and IO Informatics ("IO").  AZ provided the project environment, data resources, subject matter expertise ("SME") and business expertise.  IO provided semantic software, data modeling and integration services including solutions architecture, knowledge engineering and software engineering.</p>

    <p>The project goal was to improve search and retrieve of clinical trials data. SIEVE was to provide a web-based environment suitable for cross-study analysis.  The environment was to align across biomarkers, statistics and bioinformatics groups.  Over-arching goals included decision-making for biomarker qualification, trial design, concomitant medication analysis and translational medicine.</p>

    <p>The team analyzed approximately 42,000 trials records, identified by unique subjectIDs.  IO’s Knowledge Explorer software was used by IO’s knowledge engineers in collaboration with AZ’s SMEs to explore the content of these records as linked RDF networks.  Robust metadata descriptors were central to the integration.  RowID was applied to match entries from a diverse source documents to unique rows in unique study documents. SubjectID and studyID were also important for combining data from separate rows into an integrated resource, for example to combine 2 or more rowIDs specific to a single study subject. Because almost all docs had both subjectID and studyID, concatenation of these two items as an individual identifier allowed connections that bridged multiple documents for data traversal.  For data quality assessment, determining the error rate in making connections was possible by evaluating Gender and DOB associated with the concatenated individual identifier. About 6,000 patients could not be associated to both Gender and DOB, and were removed from corpus.  Next, as Gender and DOB information were duplicated throughout the corpus, this allowed to test the consistency of data recording, which was reasonably high. Less than 40 individuals had problematic DOB and or gender information where one or more rowIDs did not agree for a subject.  In summary, 36,000 records were found to contain valid data that could be usefully linked - each including a unique trial (StudyID), and unique and valid patient (SubjectID), and at least one row of valid laboratory data of interest.</p>

    <p>IO created a semantic data model or "application ontology" to meet SIEVE requirements.   The resulting data model and instances were harmonized by application of SPARQL-based rules and inference and were aligned with AZ standards.  Data was integrated under this ontology, loaded into a semantic database and connected to IO’s "Web Query" software.  The result is a web-based User Interface accessible to end users for cross-study searching, reporting, charting and sub-querying.  Methods include "Quick Search" options, shared searches and query building containing nesting, inclusion / exclusion, ranges, etc.  Advanced Queries are presented as filters for user entry to search subjects ("views" or "facets") including Clinical Assays, Therapy Areas, Adverse Events and Subject Demographics. Reports include exporting, charting, hyperlink mapping and results-list based searches.</p>

    <p>Results include reduced time to evaluate data from clinical trials and to facilitate forward looking decisions relevant to portfolios.  Alternatives are less efficient.  Trial data could previously be evaluated within a study; however there was no method to evaluate trials data across studies without manual intervention.  Semantic technologies applied for data description, manipulation and linking provided mission-critical value. This was particularly apparent for integration and harmonization, in light of differences discovered across resources.  IO’s Knowledge Explorer applied data visualization and manipulation, application of inference and SPARQL-based rules to RDF creation.  This resulted in efficient data modeling, transformation, harmonization and integration and helped assure a successful project.</p>

    <h3 id="s8_6">9.6 Sampling Large RDF Graphs</h3>

    <p>SampLD is a tool for sampling large RDF graphs. We use the network topology of an RDF graph to detect which triples are 'interesting' enough to be included in a sample. SampLD uses common network analysis tools such as PageRank to detect 'interesting' triples. Because we cannot directly apply pagerank to RDF graphs (as an RDF graph has labelled edges), we first apply a rewrite step where we rewrite RDF to a graph with unlabelled edges (without losing too much information). We determine the quality of the sample by how good a sample is able to return answers to a set of queries (i.e. calculating recall). (This is why we use BioPortal, as we have access to the querylogs via the USEWOD challenge). However, the performance of each sample method (i.e. combination of rewrite method + network analysis algorithm) differs between datasets. The probable reasons for these differences  are: (1) the structure of each dataset is different,  (2) the queries for each dataset have a different structure. (2), is something which we are currently analyzing by extracting important features from queries. However, (1) is still an open case. What we need are features of an RDF graph. This is where the dataset metrics are useful. They provide an easy way of generating information about the RDF structure itself.</p>

    <h3 id="s8_7">9.7 Query Formulation Using Data Metrics</h3>

    <p>YASGUI [<a href="#YASGUI">YASGUI</a>] is a query builder for SPARQL with a strong focus on usability. 
    To assist the user in formulating queries, YASGUI provides prefix autocompletion autocompletion using prefix.cc [<a href="#prefixcc">Prefix.cc</a>], endpoint autocompletion using the CKAN-based datahub.io [<a href="#Datahub">Datahub</a>], and property/class autocompletion using the LOV [<a href="#LOV">LOV</a>] API 
    However, none of these autocompletions are based on the users dataset where the query is written for.
    What users need are autocompletions based on the target dataset, in a fast and scalable manner. 
    However, querying the complete dataset for this information via SPARQL, can be expensive and slow. Additionally, the number of suggestions can be large. 
    The dataset metrics enables fetching such autocompletions in a fast manner, supporting meaningful ranking of the suggestions as well (e.g. by how often a particular class co-occurs with the current predicate).</p>

    <h3 id="s8_8">9.8 Data Providers</h3>

    <h4>9.8.1 Open PHACTS</h4>

    <p>Open PHACTS [<a href="#OpenPHACTS">OpenPHACTS</a>] is an open-source project to build a data integration platform for drug discovery data, called the Open PHACTS Discovery Platform [<a href="#Grayetal2014">Gray et al, 2014</a>]. The platform provides a domain specific API through which the integrated data can be retrieved. A key feature of the Open PHACTS Discovery Platform is that it provides provenance links back to the datasets that it has loaded, allowing the user to discover where each data point has come from. The platform is populated with open data sets including ChEMBL, UniProt, ChemSpider and Wikipathways. The data items within these datasets are related through VoID linksets [<a href="#VOID">VOID</a>]. The linksets are published as part of the delivery of the open platform.</p>

    <p>The Open PHACTS Discovery Platform aims to rely on the information in the dataset descriptions in order to enable the automatic loading of data. This requires information about the expected publication frequency of the datasets and details of the distribution files associated with a new release of a dataset, i.e. where the data can be obtained from. Once loaded, the Open PHACTS Discovery Platform computes links between the datasets. These linksets need to be published with adequate provenance information about how they were computed and upon which versions of datasets they are derived. Finally, it is important for us to be able to correctly link back to data providers to give credit and assure our users where our data has come from. To do this correctly, we need to know both human readable and machine readable provenance links to the specific files of the versions of the dataset that have been loaded.</p>

    <h4>9.8.2 EBI RDF Platform</h4>

    <p>The European Bioinformatics Institute (EBI) is the largest Bioinformatics resource provider in Europe. The recently released RDF platform [<a href="#EBI-RDF">EBI-RDF</a>] presents a coordinated effort to bring together RDF resources from multiple services and databases at the EBI. The EBI invests heavily in the curation and annotation of the source databases to ensure the most up-to-date and accurate information is readily available to the scientific community.  Given that the generated RDF is typically the result of a conversions from the source database, it is important that our users understand the relationship between the RDF and the source. To address this we publish detailed provenance for each dataset that includes important information such as version number and release date. This data is available in RDF via content-negotiation from stable dataset URIs and is described using a variety of standard meta-data vocabularies. These dataset descriptions will conform to the recommendations outlined in this document.</p>

    <h4>9.8.3 Bio2RDF</h4>

    <p>Bio2RDF [<a href="#Bio2RDF">Bio2RDF</a>] is an open-source project to provide Linked Data for the Life Sciences. Bio2RDF defines a set of simple conventions to create RDF(S) compatible Linked Data from a diverse set of heterogeneously formatted sources obtained from multiple data providers. Bio2RDF has developed a registry of over 2000 datasets that acts to provide basic information about bio-datasets and to normalize different identifiers to a common URI scheme. For each dataset, Bio2RDF provides key metadata (title, description, license, rights, publisher, creator, date created) along with a wide variety of statistics to describe the internal contents of each dataset so as to facilitate an understanding of their contents and to use in autocompletion services. Bio2RDF will implement the dataset description guidelines for the description of its datasets, the provenance of the datasets, and dataset statistics.</p>

    <h3 id="s8_9">9.9 Data Catalogs</h3>

    <h4>9.9.1 BioSharing</h4>

    <p>BioSharing [<a href="#BioSharing">BioSharing</a>] is a registry of:</p>

    <ol>
    <li>community-developed data and metadata reporting standards (including minimum information checklists, ontologies and data formats),</li>
    <li>policies related to data preservation, managing and sharing; and</li>
    <li>databases</li>
    </ol>

    <p>and the relationships between the three elements (standards, policies and databases) in the life sciences (broadly covering biological, natural and biomedical sciences). 
    Community-driven standardization efforts have worked in different domains to ensure that data and experimental details about how the data was generated are made available in an interoperable way. These are important requirements to enable science reproducibility.
    The BioSharing catalogue works to serve those seeking information on the existing standards, to identify areas where duplications or gaps in coverage exist and to promote harmonization to stop wasteful reinvention, and developing criteria to be used in evaluating standards for adoption.</p>

    <p>BioSharing also provides information about life science data, the tools that can be used to access them, the standards that have been used to generate the data or that can be used to access the data. It follows and extends the information required by the <strong>BioDBCore</strong> reporting guidelines. In particular, BioSharing identifies what reporting guidelines, terminological artifacts and/or exchange formats are considered within a particular dataset.
    BioDBCore [<a href="#BioDBCore">BioDBCore</a>, <a href="#Gaudetetal2010">Gaudet et al 2010</a>] is a checklist, or minimum information standard, including the core attributes for the description of biological databases. It is a community-driven effort overseen by the International Society for Biocuration [<a href="#ISB">ISB</a>], in collaboration with the BioSharing catalogue, which implements the BioDBCore guidelines [<a href="#BioDBCore">BioDBCore</a>]. The BioDBCore checklist main goals involve to compile information on biological databases allowing to survey the current landscape and promote the interoperability of the resources by adoption of of syntactic and semantic standards. The proposed core attributes are listed at the BioDBCore website [<a href="#BioDBCore">BioDBCore</a>].</p>

    <h4>9.9.2 Integbio Database Catalog</h4>

    <p>Integbio Database Catalog [<a href="#Integbio">Integbio</a>] is a catalog which provides basic information on life science databases according to the uniformed description items such as URLs, database description and biological species to promote circulation of the databases created in Japan. Toward our goal of covering all databases scattered within Japan, we already merged the four ministries' existing database lists into Integbio Database Catalog and also continue a survey to collect information of the databases financially supported by research funds in Japan. The content of Integbio Database Catalog is already available to users as CSV format under the Creative Commons CC0 license. Also, the CSV dataset is translated into RDF and currently exposed through a SPARQL endpoint. We participate in the discussion for the dataset description guidelines to refine the RDF dataset.</p>

    <h4>9.9.3 identifiers.org</h4>

    <p>Identifiers.org [<a href="#Identifiers.org">Identifiers.org</a>] is a system which provides resolvable and persistent URIs to identify data of interest to the life sciences. It relies upon an underlying Registry which provides detailed information on numerous resources which are crucial to scientific research. It includes details on resolving locations where records for a particular resource may be accessed, defines identifier patterns for each data provider, and reflects accessibility of data by recording the up time for individual resource. The content of the Registry is available as RDF, which is defined using DCAT. The use of such terminologies has been agreed upon by numerous communities, and enables standardised descriptions of such repositories and facilitates data sharing and processing between them.</p>

    <h3 id="s8_10">9.10 Experimental Datasets Use Case</h3>

    <p>The description of the experimental workflows in a standard way is important to understand the datasets produced and to make them re-usable for further investigations or meta-analysis. The ISA infrastructure [ISAtools] provides a format and a set of tools to manipulate it, enabling collecting, curating, managing and re-using datasets in a standards-compliant way.</p>

    <p>Originally designed for describing high-throughput genomics and post-genomics experiments, used in conjunction with other technologies, the ISA format has also been applied for the description of experiments comparing computational methods [soapdenovo2], their inputs and outputs and methods, in the form of references to Galaxy workflows.</p>

    <p>The ISA syntax provides terminology for describing sample characteristics, technologies and measurements, experimental design, instrument parameters, material and data provenance, inputs and outputs of processes and so on. The syntax relies on the annotation with ontological resources for providing domain-specific semantics. There are also tools for converting the ISA representations into RDF: ISA2RDF [ISA2RDF] produced by the ToxBank consortium [ToxBank] and ISA2OWL produced by the ISAtools team [ISAtools]. In particular, the ISA2OWL extends the representation of experimental workflows with the descriptors compliant with the guidelines presented in this document.</p>

    <p>The community of users of the ISA metadata tracking framework is the ISA commons [ISAcommons]. It includes both life science (environmental and biomedical domains) researchers and industrial participants who adopted the ISA format and the ISA tools such as ISAconfigurator and ISAcreator for curation and data collection [ISA infrastructure], Risa for interface with R packages [Risa], BII for storage [ISA infrastructure].</p>

    <p>Within the ISA community, there are examples of public repositories such as EBI Metabolights [<a href="#Metabolights">Metabolights</a>] and data publication platforms such as Nature Publishing Group Scientific Data [<a href="#ScientificData">Scientific Data</a>] and BioMedCentral-BGI GigaScience GigaDB [<a href="#GigaScience">GigaScience</a>].</p>
    
    <h2 id="acknowledgements">10 Acknowledgements</h2>
    <p>Support for HCLS activities was provided by the World Wide Web Consortium (W3C). Some initial ideas were discussed in the HCLS BioRDF task force as well as at the BioHackathon 2011 in Kyoto. M. Scott Marshall was funded by the European Commission through the EURECA (FP7-ICT-2012-6-270253) project. Alasdair J G Gray was partly funded by the Open PHACTS project an Innovative Medicines Initiative Joint Undertaking under grant agreement number 115191, resources of which are composed of financial contribution from the European Union’s Seventh Framework Programme (FP7/2007- 2013) and EFPIA com- panies’ in kind contribution.</p>

    <h2 id="references">11 References</h2>

    <dl class="bib">
    <dt><a name="Bio2RDF" id="Bio2RDF">[Bio2RDF]</a></dt>
    <dd><cite><a href="http://bio2rdf.org">http://bio2rdf.org</a></cite></dd>
    <dt><a name="BioDBCore" id="BioDBCore">[BioDBCore]</a></dt>
    <dd><cite><a href="http://biodbcore.org">http://biodbcore.org</a></cite></dd>
    <dt><a name="BioSharing" id="BioSharing">[BioSharing]</a></dt>
    <dd><cite><a href="http://biosharing.org">http://biosharing.org</a></cite></dd>
    <dt><a name="ChEMBL" id="ChEMBL">[ChEMBL]</a></dt>
    <dd><cite><a href="http://www.ebi.ac.uk/chembldb">http://www.ebi.ac.uk/chembldb</a></cite></dd>
    <dt><a name="CiTO" id="CiTO">[CiTO]</a></dt>
    <dd><cite><a href="http://purl.org/spar/cito">David Shotton and Silvio Peroni. CiTO, the Citation Typing Ontology</a></cite></dd>
    <dt><a name="Cytoscape" id="Cytoscape">[Cytoscape]</a></dt>
    <dd><cite><a href="http://cytoscape.org">http://cytoscape.org</a></cite></dd>
    <dt><a name="Datahub" id="Datahub">[Datahub]</a></dt>
    <dd><cite><a href="http://datahub.io">http://datahub.io</a></cite></dd>
    <dt><a name="Dataverse" id="Dataverse">[Dataverse]</a></dt>
    <dd><cite><a href="http://thedata.harvard.edu">Harvard Dataverse</a></cite></dd>
    <dt><a name="DCAT" id="DCAT">[DCAT]</a></dt>
    <dd><cite><a href="http://www.w3.org/TR/2014/REC-vocab-dcat-20140116">http://www.w3.org/TR/2014/REC-vocab-dcat-20140116</a></cite></dd>
    <dt><a name="DCFreq" id="DCFreq">[DCFreq]</a></dt>
    <dd><cite><a href="http://dublincore.org/groups/collections/frequency">Dublin Core Collection Description Task Group. Dublin Core Collection Description Frequency Vocabulary</a></cite></dd>
    <dt><a name="DCMI" id="DCMI">[DCMI]</a></dt>
    <dd><cite><a href="http://dublincore.org">Dublin Core Metadata Initiative</a></cite></dd>
    <dt><a name="Dryad" id="Dryad">[Dryad]</a></dt>
    <dd><cite><a href="http://datadryad.org">http://datadryad.org</a></cite></dd>
    <dt><a name="EBI-RDF" id="EBIi-RDF">[EBI-RDF]</a></dt>
    <dd><cite><a href="http://www.ebi.ac.uk/rdf">http://www.ebi.ac.uk/rdf</a></cite></dd>
    <dt><a name="FigShare" id="FigShare">[FigShare]</a></dt>
    <dd><cite><a href="http://figshare.com">http://figshare.com</a></cite></dd>
    <dt><a name="FOAF" id="FOAF">[FOAF]</a></dt>
    <dd><cite><a href="http://xmlns.com/foaf/spec">http://xmlns.com/foaf/spec</a></cite></dd>
    <dt><a name="Force11" id="Force11">[Force11]</a></dt>
    <dd><cite><a href="http://www.force11.org/catalog">http://www.force11.org/catalog</a></cite></dd>
    <dt><a name="Gaudetetal2010" id="Gaudetetal2010">[Gaudet et al 2010]</a></dt>
    <dd><cite><a href="http://nar.oxfordjournals.org/content/early/2010/11/17/nar.gkq1173.abstract">"Towards BioDBCore: a community-defined information specification for biological databases". Nucleic Acids Research, Database Issue</a></cite></dd>
    <dt><a name="Gaultonetal2011" id="Gaultonetal2011">[Gaulton et al 2011]</a></dt>
    <dd><cite><a href="http://nar.oxfordjournals.org/content/40/D1/D1100">ChEMBL: a large-scale bioactivity database for drug discovery"" Nucleic Acids Research. Volume 40. Issue D1. Pages D1100-D1107. 2011.</a></cite></dd>
    <dt><a name="Grayetal2014" id="Grayetal2014">[Gray et al 2014]</a></dt>
    <dd><cite><a href="http://dx.doi.org/10.3233/SW-2012-0088">Applying linked data approaches to pharmacology: Architectural decisions and implementation. Semantic Web Journal. 5(2):101-113. 2014.</a></cite></dd>
    <dt><a name="GigaScience" id="GigaScience">[GigaScience]</a></dt>
    <dd><cite><a href="http://www.gigasciencejournal.com">GigaScience Journal</a></cite></dd>
    <dt><a name="HCLS" id="HCLS">[HCLS]</a></dt>
    <dd><cite><a href="http://www.w3.org/blog/hcls">http://www.w3.org/blog/hcls</a></cite></dd>
    <dt><a name="IANA-MT" id="IANA-MT">[IANA-MT]</a></dt>
    <dd><cite><a href="http://www.iana.org/assignments/media-types/media-types.xhtml">http://www.iana.org/assignments/media-types/media-types.xhtml</a></cite></dd>
    <dt><a name="Identifiers.org" id="Identifiers.org">[Identifiers.org]</a></dt>
    <dd><cite><a href="http://identifiers.org">Identifiers.org Registry</a></cite></dd>
    <dt><a name="Integbio" id="Integbio">[Integbio]</a></dt>
    <dd><cite><a href="http://integbio.jp/dbcatalog/?lang=en">http://integbio.jp/dbcatalog/?lang=en</a></cite></dd>
    <dt><a name="ISB" id="ISB">[ISB]</a></dt>
    <dd><cite><a href="http://www.biocurator.org">http://www.biocurator.org</a></cite></dd>
    <dt><a name="Lexvo" id="LexvoPaper">[Lexvo]</a></dt>
    <dd><cite><a href="http://www.semantic-web-journal.net/content/lexvoorg-language-related-information-linguistic-linked-data-cloud-0">Gerard de Melo. Lexvo.org: Language-Related Information for the Linguistic Linked Data Cloud. Submitted to Semantic Web Journal.</a></cite></dd>
    <dt><a name="LOV" id="LOV">[LOV]</a></dt>
    <dd><cite><a href="http://lov.okfn.org/">Linked Open Vocabularies</a></cite></dd>
    <dt><a name="Metabolights" id="Metabolights">[Metabolights]</a></dt>
    <dd><cite><a href="http://www.ebi.ac.uk/metabolights/">http://www.ebi.ac.uk/metabolights/</a></cite></dd>
    <dt><a name="NIF" id="NIF">[NIF]</a></dt>
    <dd><cite><a href="http://www.neuinfo.org">http://www.neuinfo.org</a></cite></dd>
    <dt><a name="OpenPHACTS" id="OpenPHACTS">[OpenPHACTS]</a></dt>
    <dd><cite><a href="http://www.openphacts.org">http://www.openphacts.org</a></cite></dd>
    <dt><a name="OPM" id="OPM">[OPM]</a></dt>
    <dd><cite><a href="http://openprovenance.org/">Luc Moreau, Ben Clifford, Juliana Freire, Joe Futrelle, Yolanda Gil, Paul Groth, Natalia Kwasnikowska, Simon Miles, Paolo Missier, Jim Myers, Beth Plale, Yogesh Simmhan, Eric Stephan, and Jan Van den Bussche. The open provenance model core specification (v1.1). Future Generation Computer Systems, July 2010. doi: 10.1016</a></cite></dd>
    <dt><a name="OPMW" id="OPMW">[OPMW]</a></dt>
    <dd><cite><a href="http://www.opmw.org/">"Towards Open Publication of Reusable Scientific Workflows: Abstractions, Standards, and Linked Data". Garijo, D., and Gil, Y. Internal Project Report, January 2012</a></cite></dd>
    <dt><a name="ORCID" id="ORCID">[ORCID]</a></dt>
    <dd><cite><a href="http://orcid.org">http://orcid.org</a></cite></dd>
    <dt><a name="PAV" id="PAV">[PAV]</a></dt>
    <dd><cite><a href="http://purl.org/pav">Paolo Ciccarese and Stian Soiland-Reyes. Provenance, authoring and versioning Ontology</a>.</cite></dd>
    <dd><cite>Ciccarese, P.; Soiland-Reyes, S.; Belhajjame, K.; Gray, A. J. G.; Goble, C. and Clark, T. PAV ontology: Provenance, Authoring and Versioning. In Journal of Biomedical Semantics, 2013.</cite></dd>
    <dt><a name="prefixcc" id="prefixcc">[Prefix.cc]</a></dt>
    <dd><cite><a href="http://prefix.cc">http://prefix.cc</a></cite></dd>
    <dt><a name="PROV" id="PROV">[PROV]</a></dt>
    <dd><cite><a href="http://www.w3.org/TR/prov-overview">http://www.w3.org/TR/prov-overview</a></cite></dd>
    <dt><a name="RDF" id="RDF">[RDF]</a></dt>
    <dd><cite><a href="http://www.w3.org/TR/rdf-primer">http://www.w3.org/TR/rdf-primer</a></cite></dd>
    <dt><a name="RDFS" id="RDFS">[RDFS]</a></dt>
    <dd><cite><a href="http://www.w3.org/TR/rdf-schema/">http://www.w3.org/TR/rdf-schema/</a></cite></dd>
    <dt><a name="RFC2119" id="RFC2119">[RFC2119]</a></dt>
    <dd><cite><a href="https://www.ietf.org/rfc/rfc2119.txt">https://www.ietf.org/rfc/rfc2119.txt</a></cite></dd>
    <dt><a name="SCHEMA" id="SCHEMA">[SCHEMA]</a></dt>
    <dd><cite><a href="http://schema.org/Dataset">http://schema.org/Dataset</a></cite></dd>
    <dt><a name="ScientificData" id="ScientificData">[ScientificData]</a></dt>
    <dd><cite><a href="http://nature.com/scientificdata">Nature Publishing Group’s Scientific Data</a></cite></dd>
    <dt><a name="SPARQL" id="SPARQL">[SPARQL]</a></dt>
    <dd><cite><a href="http://www.w3.org/TR/sparql11-overview/">SPARQL 1.1</a></cite></dd>
    <dt><a name="TavernaProvenance" id="TavernaProvenance">[TavernaProvenance]</a></dt>
    <dd><cite><a href="http://www.taverna.org.uk/documentation/taverna-2-x/provenance">http://www.taverna.org.uk/documentation/taverna-2-x/provenance</a></cite></dd>
    <dt><a name="TavernaProv" id="TavernaProv">[TavernaProv]</a></dt>
    <dd><cite><a href="http://ns.taverna.org.uk/2012/tavernaprov/">http://ns.taverna.org.uk/2012/tavernaprov/</a></cite></dd>
    <dt><a name="VIVO" id="VIVO">[VIVO]</a></dt>
    <dd><cite><a href="https://wiki.duraspace.org/display/VIVO/VIVO-ISF+Ontology">https://wiki.duraspace.org/display/VIVO/VIVO-ISF+Ontology</a></cite></dd>
    <dt><a name="VOID" id="VOID">[VOID]</a></dt>
    <dd><cite><a href="http://www.w3.org/TR/void">http://www.w3.org/TR/void</a></cite></dd>
    <dt><a name="VOID-SPARQL" id="VOID-SPARQL">[VOID-SPARQL]</a></dt>
    <dd><cite><a href="https://code.google.com/p/void-impl/wiki/SPARQLQueriesForStatistics">https://code.google.com/p/void-impl/wiki/SPARQLQueriesForStatistics</a></cite></dd>
    <dt><a name="wf4ever" id="wf4ever">[wf4ever]</a></dt>
    <dd><cite><a href="http://www.wf4ever-project.org/">Belhajjame K, Corcho O, Garijo D, Zhao J, Missier P, Newman DR, Palma R,  Bechhofer S, Garcia-Cuesta E, Gómez-Pérez JM, Klyne G, Page K, Roos M, Ruiz JE, Soiland-Reyes S, Verdes-Montenegro L, De Roure D, Goble CA: Workflow-Centric Research Objects: A First Class Citizen in the Scholarly Discourse. In proceedings of the ESWC2012 Workshop on the Future of Scholarly Communication in the Semantic Web (SePublica2012), Heraklion, Greece, May 2012</a></cite></dd>
    <dt><a name="WormBase" id="WormBase">[WormBase]</a></dt>
    <dd><cite><a href="http://www.wormbase.org">http://www.wormbase.org</a></cite></dd>
    <dt><a name="YASGUI" id="YASGUI">[YASGUI]</a></dt>
    <dd><cite><a href="http://yasgui.org">http://yasgui.org</a></cite></dd>
    </dl>

    <h2 id="appendix">12 Appendix</h2>
    
    <h3 id="appendix_1">12.1 Complete Example of a Dataset Description</h3>

    <p>The following example summarizes the presented dataset description recommendations. Numerical placeholders have been replaced by example values.</p>

<pre>
@prefix : &lt;http://w3.org/hclsdatasetdescriptionsexample&gt; .
@prefix cito: &lt;http://purl.org/spar/cito/&gt; .
@prefix dcat: &lt;http://www.w3.org/ns/dcat#&gt; .
@prefix dctypes: &lt;http://purl.org/dc/dcmitype/&gt; .
@prefix dct: &lt;http://purl.org/dc/terms/&gt; .
@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .
@prefix freq: &lt;http://purl.org/cld/freq/&gt; .
@prefix idot: &lt;http://identifiers.org/idot/&gt; .
@prefix lexvo: &lt;http://lexvo.org/ontology#&gt; .
@prefix ncit: &lt;http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#&gt; .
@prefix pav: &lt;http://purl.org/pav/&gt; .
@prefix prov: &lt;http://www.w3.org/ns/prov#&gt; .
@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .
@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .
@prefix schemaorg: &lt;http://schema.org/&gt; .
@prefix sd: &lt;http://www.w3.org/ns/sparql-service-description#&gt; .
@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .
@prefix void: &lt;http://www.w3.org/TR/void/&gt; .

# Summary Level Description
:chembl a dctypes:Dataset .

# Version Level Description
:chembl17 a dctypes:Dataset ;
    dct:isVersionOf :chembl;
    pav:version "17.0";
    dcat:distribution :chembl17rdf, 
      :chembl17relational, :chembl17csv .

# Distribution Level Descriptions
:chembl17rdf a dcat:Distribution, void:Dataset .
:chembl17relational a dcat:Distribution .
:chembl17csv a dcat:Distribution .
    
:chembl 
    rdf:type dctypes:Dataset .
    
:chembl
       dct:title "ChEMBL"@en ;
       dct:alternative "ChEMBLdb"@en ;
       dct:identifier "chembl"@en .
    
:chembl 
    dct:description "ChEMBL is a database of bioactive compounds, their quantitative properties and bioactivities (binding constants, pharmacology and ADMET, etc). The data is abstracted and curated from the primary scientific literature."@en .
    
:chembl17 
    dct:issued "2013-08-29"^^xsd:date .
    
:chembl17
    dct:creator &lt;https://www.ebi.ac.uk/chembl/&gt; .

:chembl_target_targetcmpt_linkset 
    pav:authoredBy &lt;http://orcid.org/0000-0002-8011-0300&gt; .
    
:chembl 
    dct:publisher &lt;http://www.ebi.ac.uk&gt; .
    
:chembl 
    foaf:page &lt;http://www.ebi.ac.uk/chembl/&gt; ;
    schemaorg:logo &lt;http://www.ebi.ac.uk/rdf/sites/ebi.ac.uk.rdf/files/resize/images/rdf/chembl_service_logo-146x48.gif&gt; .
    
:chembl 
    dcat:theme ncit:C48807 ; # chemical
    dcat:keyword "chemical"^^xsd:string, "assay"^^xsd:string .
    
:chembl
    dct:license &lt;http://creativecommons.org/licenses/by-sa/3.0/&gt; ;
    dct:rights """The data in ChEMBL is covered by the Creative Commons By Attribution. 
Under the -BY clause, we request attribution for subsequent use of ChEMBL.  
For publications using ChEMBL data, the primary current citation is: 

1.  A. Gaulton, L. Bellis, J. Chambers, M. Davies, A. Hersey, Y. Light, S. McGlinchey, R. Akhtar, A.P. Bento, B. Al-Lazikani, D. Michalovich, &amp; J.P. Overington (2012) 'ChEMBL: A Large-scale Bioactivity Database For Chemical Biology and Drug Discovery' Nucl. Acids Res. Database Issue. 40 D1100-1107 DOI:10.1093/nar/gkr777 PMID:21948594

If ChEMBL is incorporated into other works, we ask that the ChEMBL IDs are preserved, 
and that the release number of ChEMBL is clearly displayed.""" .
    
:chembl
    dct:language &lt;http://lexvo.org/id/iso639-3/en&gt; .
    
:chembl
    cito:citesAsAuthority &lt;http://nar.oxfordjournals.org/content/40/D1/D1100&gt; .
    
:chembl 
    void:vocabulary &lt;http://rdf.ebi.ac.uk/terms/chembl#&gt;, &lt;http://www.w3.org/ns/dcat#&gt;, &lt;http://purl.org/dc/terms/&gt; .
    
:chembl17
    dct:conformsTo &lt;http://www.w3.org/2001/sw/hcls/notes/hcls-dataset/&gt; .
    
:chembl 
    dct:hasPart :chembl17_rdf_molecule_dataset, :chembl17_rdf_target_dataset .
    
:chembl
    idot:preferredPrefix "chembl" ;
    idot:alternatePrefix "chembldb" .
    
:chembl17
    idot:identifierPattern "CHEMBL\\d+"^^xsd:string .
    
:chembl17rdf
    void:uriRegexPattern "http://rdf.ebi.ac.uk/resource/chembl/target/CHEMBL\\d+" .
    
:chembl
    idot:accessPattern
        &lt;http://www.ebi.ac.uk/chembl/compound/inspect/&gt; ,
        &lt;http://identifiers.org/chembl.compound/&gt; ,
        &lt;http://bio2rdf.org/chembl&gt; ,
        &lt;http://linkedchemistry.info/chembl/chemblid&gt; .

&lt;http://www.ebi.ac.uk/chembl/compound/inspect/&gt;
    idot:primarySource true ;
    dct:format "text/html" ;
    dct:publisher "http://www.ebi.ac.uk" ;
    a idot:AccessPattern .

&lt;http://identifiers.org/chembl.compound/&gt;
    dct:format "text/html" ;
    a idot:AccessPattern .

&lt;http://bio2rdf.org/chembl&gt;
    dct:format "application/rdf+xml" ;
    dct:publisher "http://bio2rdf.org" ;
    a idot:AccessPattern .

&lt;http://linkedchemistry.info/chembl/chemblid&gt;
    dct:format "application/rdf+xml" ;
    a idot:AccessPattern .
    
:chembl
    idot:exampleIdentifier "CHEMBL25"^^xsd:string .
    
:chembl17rdf
    void:exampleResource &lt;http://rdf.ebi.ac.uk/resource/chembl/compound/CHEMBL25&gt; .
    
:chembl17 
    dct:isVersionOf :chembl .
    
:chembl17
    pav:version "17"^^xsd:string .
    
:chembl17
    pav:previousVersion :chembl16 .
    
:chembl
    pav:hasCurrentVersion :chembl17 .
    
:chembl
    dct:source :pubchem-bioassay-09-01-2014 .
    
:chembl17rdf
    pav:createdWith :chembl-sql2rdf-exporter-v1 .
    
:chembl-compound
    sio:is-data-item-in :chembl17rdf .
    
:chembl
    dct:accrualPeriodicity freq:quarterly .
    
:chembl17-1
    pav:previousVersion :chembl17 .
    
:chembl17
    dcat:distribution :chembl17rdf, :chembl17db .

:chembl17rdf 
    a dctypes:Dataset, void:Dataset ;
    dct:format "text/turtle" ;
    dct:format &lt;http://www.w3.org/ns/formats/Turtle&gt; ;
    dct:format "application/gzip" .

:chembl17db
    a dctypes:Dataset ;
    dct:format "application/sql" .
    
:chembl
    dcat:accessURL &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb&gt; .

:chembl17
    dcat:accessURL &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_17/&gt; .

:chembl17sql
    dcat:downloadURL &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_17/chembl_17_mysql.tar.gz&gt; ;
    dcat:byteSize "861443887"^^xsd:decimal .

:chembl17rdf
    void:dataDump &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBL-RDF/17/chembl_17_molecule.ttl.gz&gt; .
    
:service
    a sd:Service ;
    sd:defaultDatasetDescription [
        a sd:Dataset ;
        sd:defaultGraph [
            a sd:Graph ;
            dct:source :chembl17rdf ;
        ] ;
    ] .
    
:chembl17
    dcat:landingPage &lt;ftp://ftp.ebi.ac.uk/pub/databases/chembl/ChEMBLdb/releases/chembl_17/chembl_17_release_notes.txt&gt; .
    
:rdfdataset
    void:triples "1492029"^^xsd:integer .
    
:rdfdataset
    void:entities "982739"^^xsd:integer .
    
:rdfdataset
    void:distinctSubjects "822920"^^xsd:integer .
    
:rdfdataset
    void:properties "208"^^xsd:integer .
    
:rdfdataset
    void:distinctObjects "1209321"^^xsd:integer .
    
:rdfdataset
    void:classPartition [
        void:class rdfs:Class ;
        void:entities "291"^^xsd:integer
    ] .
    
:rdfdataset
    void:classPartition [
        void:class rdfs:Literal ;
        void:entities "782032"^^xsd:integer
    ] .
    
:rdfdataset
    void:classPartition [
        void:class sd:Graph ;
        void:entities "3"^^xsd:integer
    ].
    
:rdfdataset
    void:classPartition [
        void:class &lt;http://linkedchemistry.info/chembl/assay/a93337&gt; ;
        void:entities "14"^^xsd:integer
    ] .
    
:rdfdataset
    void:propertyPartition [
        void:property &lt;http://semanticscience.org/resource/SIO_000300&gt; ;
        void:triples "79"^^xsd:integer
    ] .
    
:rdfdataset
    void:subset [
        a void:LinkSet ;
        void:linkPredicate &lt;http://semanticscience.org/resource/SIO_000300&gt; ;
        void:objectsTarget [
            void:class rdfs:Class ;
            void:entities "68"^^xsd:integer
        ]
    ] .
    
:rdfdataset
    void:subset [
        a void:LinkSet ;
        void:linkPredicate &lt;http://semanticscience.org/resource/SIO_000300&gt; ;
        void:objectsTarget [
            void:class rdfs:Literal;
            void:entities "288"^^xsd:integer
        ]
    ] .
    
:rdfdataset
    void:subset [
        a void:LinkSet ; 
        void:linkPredicate &lt;http://semanticscience.org/resource/SIO_000300&gt; ;
        void:subjectsTarget [
            void:class &lt;http://linkedchemistry.info/chembl/chemblid/CHEMBL702808/chemblid&gt; ;
            void:entities "88102"^^xsd:integer ;
            void:objectsTarget [
                void:class &lt;http://rdf.farmbio.uu.se/chembl/onto/#Assay&gt; ;
                void:entities "2819"^^xsd:integer
            ] 
        ]
    ] .
    
:rdfdataset
    void:subset [
        a void:LinkSet ;
        void:linkPredicate &lt;http://semanticscience.org/resource/SIO_000300&gt; ;
        void:subjectsTarget &lt;http://linkedchemistry.info/chembl/assay/a93337&gt; ; 
        void:objectsTarget &lt;http://linkedchemistry.info/chembl/resource/r13299&gt; ;
        void:triples "281902"^^xsd:integer
    ] .
</pre>

    <div class="changes">
      <h2 id="chlog">Change Log</h2>
    </div>
      
    <div class="nav"><a href="http://validator.w3.org/check/referer">
      <img src="http://www.w3.org/Icons/valid-xhtml10" alt="Valid XHTML 1.0!" height="31" width="88" /></a>
    </div><hr></hr>

  </body>

</html>
